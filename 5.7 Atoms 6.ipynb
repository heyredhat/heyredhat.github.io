{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is an atom?\n",
    "## 6. A polynomial?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we should expect that the complex numbers will be our atoms, and we'll form composites out of them. What are these composites? You've probably heard of them before: they are *polynomials*. Indeed, we will now take for our composites \"equations\" themselves.\n",
    "\n",
    "Recall that a polynomial is defined quite like a \"base-n\" number, but what before was the \"base\" is now a *variable*. The $c_{n}$ are generally complex coefficients.\n",
    "\n",
    "$ f(z) = \\dots + c_{4}z^{4} +  c_{3}z^{3} + c_{2}z^{2} + c_{1}z + c_{0} $\n",
    "\n",
    "Two important things we can do to polynomials are differentiate and integrate them.\n",
    "\n",
    "For instance, $\\frac{d}{dz} x^{2} = 2x$. And inversely: $\\int 2x dx = x^{2} + C$, where we also add a constant C, since when we differentiate it, it will go to zero (so we can't rule out it's not there). \n",
    "\n",
    "We can have polynomials with a finite number of terms, but we could also have infinite polynomials. Here's an interesting fact. \n",
    "\n",
    "The meaning of the derivative of a function $\\frac{d}{dx} f(x)$ is the change with regard to x at the input value. For a real valued function, you can imagine it like the slope of the line tangent to the curve at that point. You can imagine choosing two points on the curve, and bringing them infinitesimally close together, so that you get a linear approximation to the curve at that point. Inversely, integration is like summing the area under a curve with little rectangles, and imagining shrinking the size of the rectangles to be infinitesimally small.\n",
    "\n",
    "Check out this image of $sin(x)$ and $cos(x)$:\n",
    "\n",
    "![](img/sine_cosine.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It happens that $\\frac{d}{dx} sin(x) = cos(x)$ and $\\frac{d}{dx} cos(x) = -sin(x)$. You can see this visually. When sine is at its peak, its tangent line is a horizontal line: $\\frac{\\Delta rise}{\\Delta run} = \\frac{0}{1}$. And behold: cosine is 0 there! And when cosine has a peak, sine is 0! And this holds the whole way through. \n",
    "\n",
    "Notice $\\frac{d}{dx} sin(x) = cos(x) \\rightarrow \\frac{d}{dx} cos(x) = -sin(x) \\rightarrow \\frac{d}{dx} -sin(x) = -cos(x) \\rightarrow \\frac{d}{dx} -cos(x) = sin(x)$, and we come full circle. Whereas a finite dimensional polynomial will eventually give you 0 if you differentiate it enough times, an \"infinite dimensional polynomial\" can be differentiated an infinite number of times.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a nice theorem that infinitely differentiable functions can be expressed as \"Taylor polynomials\":\n",
    "\n",
    "$f_{a}(x) = f(a) + \\frac{f^{\\prime}(a)}{1!}(x-a) + \\frac{f^{\\prime\\prime}(a)}{2!}(x-a)^{2} + \\frac{f^{\\prime\\prime\\prime}(a)}{3!}(x-a)^{3} + \\dots$, where $n! = n(n-1)(n-2)\\dots (1)$ and $f^{(n)}$ means take the $n^{th}$ derivative.\n",
    "\n",
    "In other words, $f_{a}(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!}(x-a)^{n}$.\n",
    "\n",
    "In the case of sine and cosine (evaluated at 0):\n",
    "\n",
    "$sin(x) = sin(0) + \\frac{cos(0)}{1!}x - \\frac{1}{2!}sin(0)x^{2} - \\frac{1}{3!}cos(0)x^{3} + \\frac{1}{4!}sin(0)x^{4} + \\dots$\n",
    "\n",
    "$cos(x) = cos(0) - \\frac{sin(0)}{1!}x - \\frac{1}{2!}cos(0)x^{2} + \\frac{1}{3!}sin(0)x^{3} + \\frac{1}{4!}cos(0)x^{4} + \\dots$\n",
    "\n",
    "But since $sin(0) = 0$ and $cos(0) = 1$, these are just:\n",
    "\n",
    "$sin(x) =  x - \\frac{x^{3}}{3!} + \\frac{x^{5}}{5!} - \\dots = \\sum_{n=0}^{\\infty} \\frac{(-1)^{n}x^{2n+1}}{(2n+1)!}$\n",
    "\n",
    "$cos(x) =  1 - \\frac{x^{2}}{2!} + \\frac{x^{4}}{4!} - \\dots = \\sum_{n=0}^{\\infty} \\frac{(-1)^{n}x^{2n}}{(2n)!}$\n",
    "\n",
    "So now we can approximate sine and cosines by evaluating the terms of this series! They are \"transcendental\" functions in the sense that they aren't equal to any *finite* polynomial: they can only be reached with an infinite amount of algebra!\n",
    "\n",
    "You may know that the exponential function is the magical function which is own derivative: \n",
    "\n",
    "$\\frac{d}{dx} e^{x} = e^{x}$. Since $e^{0} = 1$, $e^{x} = \\sum_{n=0}^{\\infty} \\frac{x^{n}}{n!} = \\frac{1}{0!} + \\frac{x}{1!} + \\frac{x^{2}}{2!} + \\frac{x^{3}}{3!} + \\frac{x^{4}}{4!}\\dots$.\n",
    "\n",
    "We then work out the series for $e^{ix} = \\frac{1}{0!} + i\\frac{x}{1!} - \\frac{x^{2}}{2!} - i\\frac{x^{3}}{3!} + \\frac{x^{4}}{4!} + \\dots$.\n",
    "\n",
    "Rearranging things we have: $ e^{ix} = \\Big{(} 1 - \\frac{x^{2}}{2!} + \\frac{x^{4}}{4!} + \\dots \\Big{)} + i\\Big{(} x - \\frac{x^{3}}{3!} + \\frac{1}{5!}x^{5} + \\dots \\Big{)}$. In other words: $e^{ix} = cos(x) + isin(x)$, as we promised before. As you wind around the unit circle, the x-coordinate traces out $cos(x)$ and the y-coordinate traces out $sin(x)$.\n",
    "\n",
    "For now, however, let's consider finite polynomials. They are their own Taylor polynomials.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classic problem is to solve for the \"roots\" of $f(z)$. These are the values of $z$ that make $f(z) = 0$. \n",
    "\n",
    "The degree of a polynomial is the highest power of the variable that appears within it. It turns out that a degree $n$ polynomial has exactly $n$  complex roots. A polynomial can therefore be factored into roots, just as a whole number can be factored into primes.\n",
    "\n",
    "$ f(z) =  \\dots + c_{4}z^{4} +  c_{3}z^{3} + c_{2}z^{2} + c_{1}z + c_{0} = (z - \\alpha_{0})(z - \\alpha_{1})(z - \\alpha_{2})\\dots $\n",
    "\n",
    "The only catch is that the roots of the polynomial $f(z)$ are left invariant if you multiply the whole polynomial by any complex number. So the roots define the polynomial up to multiplication by a complex \"scalar.\" (By the way, you can think about infinite dimesional polynomials as being determined by their infinite roots using something called the Weierstrass Factorization Theorem.)\n",
    "\n",
    "The proof of this is called the fundamental theorem of algebra, just as the proof that whole numbers can be uniquely decomposed into primes is called the fundamental theorem of arithmetic. Interestingly, the proof doesn't require much more than some geometry. Here's a brief sketch. First it's worth recalling that: for some complex $z = re^{i\\theta}$, then $z^{n} = r^{n}e^{in\\theta}$.\n",
    "\n",
    "So suppose we have some polynomial $ f(z) = c_{n}z^n + \\dots + c_{4}z^{4} +  c_{3}z^{3} + c_{2}z^{2} + c_{1}z + c_{0}$. Now suppose that we take $z$ to be very large. For a very large $z$ the difference between $z^{n-1}$ and $z^n$ is considerable, and we can say that the polynomial is dominated by the $c_{n}z^n$ term. Now imagine tracing out a big circle in the complex plane corresponding to different values of $z$. If we look at $f(z)$, it'll similarly wind around a circle $n$ times as fast (with a little wiggling as it does so corresponding to the other tiny terms). Now imagine shrinking the $z$ circle down smaller and smaller until $z=0$. But $f(z=0) = c_{0}$, which is just the constant term. So as the \"input\" circle shrinks down to 0, the \"output\" circle shrinks down to $c_{0}$. To get there, however, the shrinking circle in the output plane must have passed the origin at some point, and therefore the polynomial has at least one root. You factor that root out of the polynomial leading to a polynomial of one less degree, and repeat the argument, until there are no more roots left. Therefore, a degree $n$ polynomial has exactly $n$ roots in the complex numbers.\n",
    "\n",
    "![](img/fundamental_theorem_of_algebra.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is related to the fact that the complex numbers represent the algebraic closure of the elementary operations of arithmetic. One could consider other number fields: the real numbers, for instance: and then there might not be exactly $n$ roots for a degree $n$ polynomial.\n",
    "\n",
    "If you want to find some roots, you could try like Renaissance Italian mathematicians to do so in public contests for popular acclaim. Or you could try to approximate them. For example, try Newton's method, given some starting guess $g_{0}$:\n",
    "\n",
    "$g_{n+1} = g_{n} - \\frac{f(g_{n})}{f^{\\prime}(g_{n})}$\n",
    "\n",
    "![](img/newtons_method.png)\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "It's worth noting \"Vieta's formulas\" which relate the roots to the coefficients:\n",
    "\n",
    "Given a polynomial $f(z) = c_{n}z^n + \\dots + c_{4}z^{4} +  c_{3}z^{3} + c_{2}z^{2} + c_{1}z + c_{0} = (z - \\alpha_{0})(z - \\alpha_{1})(z - \\alpha_{2})\\dots(z - \\alpha_{n-1}) $, we find:\n",
    "\n",
    "$ 1 = \\frac{c_{n}}{c_{n}}$ \n",
    "\n",
    "$ \\alpha_{0} + \\alpha_{1} + \\alpha_{2} + \\dots + \\alpha_{n-1} = -\\frac{c_{n-1}}{c_{n}}$\n",
    "\n",
    "$ \\alpha_{0}\\alpha_{1} + \\alpha_{0}\\alpha_{2} + \\dots + \\alpha_{1}\\alpha_{2} + \\dots + \\alpha_{2}\\alpha_{3} \\dots = \\frac{c_{n-2}}{c_{n}}$\n",
    "\n",
    "$ \\alpha_{0}\\alpha_{1}\\alpha_{2} + \\alpha_{0}\\alpha_{1}\\alpha_{3} + \\dots + \\alpha_{1}\\alpha_{2}\\alpha_{3} + \\dots + \\alpha_{2}\\alpha_{3}\\alpha_{4} \\dots = - \\frac{c_{n-3}}{c_{n}}$\n",
    "\n",
    "$ \\vdots $\n",
    "\n",
    "$ \\alpha_{0}\\alpha_{1}\\alpha_{2}\\dots = (-1)^{n}\\frac{c_{0}}{c_{n}} $ \n",
    "\n",
    "In other words, the $c_{n-1}$ coefficient is the sum of roots taken one at a time times $(-1)^{1}$, the $c_{n-2}$ coefficient is given by the sum of the roots taken two at a time times $(-1)^{2}$, and so on, until the constant term is given by the product of the roots times $(-1)^{n}$, in other words the $n$ roots taken all at a time. We divide out by $c_{n}$ as the roots are defined up to multiplication by a complex sclar.\n",
    "\n",
    "In other words, the relationship between coefficients and roots is \"holistic\"--just like the relationship between a composite whole number and its prime factors, the latter of which are contained \"unordered\" within it. Each of the coefficients depends on *all the roots*. Moreover, by taking the roots 0 at a time, 1 at a time, 2 at a time, etc, we get an *ordered* representation from an *unordered* one.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One consequence of this which will be very consequential is that polynomials form a \"vector space.\" A vector space consists of multidimensional arrows called \"vectors\" and \"scalars,\" the latter of which are just normal numbers. You can multiply vectors by scalars, and add vectors together, and you'll always get a vector in the vector space. Think of the monomials, the powers of $z$ as being basis vectors!\n",
    "\n",
    "Implicitly, we've worked with real vector spaces when we used $(x, y)$ and $(x, y, z)$ coordinates, projective or otherwise. Here, we're working with complex vector spaces, since we allow our polynomials to have complex coefficients. (Note we could use other \"division algebras\" for our scalars: reals, complex numbers, quaternions, or octonions, but complex numbers give us all we need.) But just like real vector spaces, the point is that we can expand any vector in some \"basis.\" For real 3D vectors, we often use $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$. The idea is that any 3D point can be written as a linear combination of these three vectors, which are orthonormal: they are at right angles, and of unit length. Eg. $(x, y, z) = x(1,0,0) + y(0,1,0) + z(0,0,1)$. Any set of linearly independent vectors can form a basis, although we'll stick to using orthonormal vectors.\n",
    "\n",
    "In real vector spaces, the length of a vector is given by $\\sqrt{v \\cdot v}$, where $v \\cdot v$ is the inner product: you multiply the entries of the two vectors pairwise and sum. This is just the Pythagorean theorem in disguise. Given $\\begin{pmatrix}x \\\\ y\\end{pmatrix}$, it's length is $\\sqrt{xx + yy}$. \n",
    "\n",
    "If you take $u \\cdot v$, this quantity will be 0 if the vectors are at right angles: $u \\cdot v = |u|v|cos(\\theta)$, where $|u|$ and $|v|$ are the lengths of the vector and $\\theta$ is the angle between them. For complex vector spaces, we'll use the bracket notation $\\langle v \\mid v \\rangle$, where recall that the $\\langle v \\mid$ is a bra, which is the complex conjugated row vector corresponding to the column vector $\\mid v \\rangle$. So the inner product for complex vectors is a complex number, and there's much one can say about it, including the fact that there are many different inner products you can define, but just like we expect, if the vectors are orthogonal, the inner product is 0.\n",
    "\n",
    "Notice already that when we add two complex vectors, the individual components can cancel out in a whole circle's worth of directions, not just in terms of positive and negative. This is what leads to \"quantum intererence.\"\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, already this is looking like quantum mechanics. Indeed, in what follows, we'll be using polynomials to represent quantum spin states. You should note that while the exposition has been more or less self-contained so far, in what follows we'll be assuming knowledge from some of the previous essays!\n",
    "\n",
    "For example, we've already alluded to the fact that instead of working with $\\mathbb{C} + \\infty$, we can work in the two dimensional complex projective space: aka the complex projective line. It's just the real projective line complexified! Given some $\\alpha$ which can be a complex number or infinity:\n",
    "\n",
    "$\\alpha \\rightarrow \\begin{pmatrix} 1 \\\\ \\alpha \\end{pmatrix}$ or $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$ if $\\alpha = \\infty$.\n",
    "\n",
    "In reverse:\n",
    "\n",
    "$ \\begin{pmatrix} a \\\\ b \\end{pmatrix} \\rightarrow \\frac{b}{a}$ or $\\infty$ if $a=0$.\n",
    "\n",
    "We're free to multiply this complex vector by any complex number and this won't change the root, so we can always normalize the vector so its length is 1. Then it represents the state of a qubit, a spin-$\\frac{1}{2}$ particle, consisting of an average spin-axis (a point on the sphere), and a complex phase. Supposing we've quantized along the Z-axis, then $aa^{*}$ is the probability of measuring this qubit to be $\\uparrow$ along the Z direction, and $bb^{*}$ is the probability of measuring it to be $\\downarrow$. (\"Quantized along the Z-axis\" just means that we take eigenstates of the Pauli Z operator to be our basis states, so that each component of our complex vector weights one of those eigenstates. All Hermitian matrices have eigenvectors (aka eigenstates) which form an orthogonal basis.) We've already talked quite a bit about qubits in previous encounters so I won't review the details here. \n",
    "\n",
    "It's worth noting that if we look at the normalization condition: $aa^{*} + bb^{*} = 1$, and expand out the complex and imaginary parts of each, we get: $\\alpha^{2} + \\beta^{2} + \\gamma^{2} + \\delta^{2} = 1$. If $\\alpha^{2} + \\beta^{2} = 1$ is a point on a circle, and $\\alpha^{2} + \\beta^{2} + \\gamma^{2} = 1$ is a point on a sphere, then $\\alpha^{2} + \\beta^{2} + \\gamma^{2} + \\delta^{2} = 1$ is a point on a 3-sphere: the 3-sphere lives in four dimensional space, and just as a circle is a 1D space that loops back on itself, so that if you go too far in one direction, you come out in the opposite direction, and the sphere is a 2D space that loops around, you can think of the 3-sphere as a 3D space that if you go forever in one direction, you loop back around. But we also know from the above, that we can break down a point on a 3-sphere as: a point on a 2-sphere, plus a complex phase, a point on the circle. This is known as the \"Hopf fibration.\" The idea is that you can think of the 2-sphere as a \"base space\" with a little \"fiber\" (the phase) living above each point. There's actually 4 of these (non-trivial) fibrations, corresponding to the 4 division algebras. The 1-sphere breaks into 1-sphere with a 0-sphere (just two equidistant points!) at each point (reals). The 3-sphere breaks into the 2-sphere with a 1-sphere at each point (complex). The 7-sphere breaks into a 4-sphere with a 3-sphere living at each point (quaternions). And a 15-sphere breaks into an 8-sphere with a 7-sphere living at each point (octonians). Others can go into more detail! (There's an interesting connection in the latter two cases between the entanglement between two and three qubits.)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway, now we can see another way of thinking about our projective vectors. It's the difference between considering a \"root\" vs a \"monomial\".\n",
    "\n",
    "Suppose we have a polynomial with a single root, a monomial: $f(z) = c_{1}z + c_{0}$. Let's solve it:\n",
    "\n",
    "$ 0 = c_{1}z + c_{0}$\n",
    "\n",
    "$ z = -\\frac{c_{0}}{c_{1}} $\n",
    "\n",
    "Indeed, we could have written $f(z) = (z + c_{0}/c_{1})$. The point is that the monomial can be identified with its root up to multiplication by any complex number--just like our complex projective vector!\n",
    "\n",
    "So if we had some complex number $\\alpha$, which we upgraded to a complex projective vector, we could turn it into a monomial by remembering about that negative sign:\n",
    "\n",
    "$\\alpha \\rightarrow \\begin{pmatrix} 1 \\\\ \\alpha  \\end{pmatrix}  \\rightarrow f(z) = 1z -\\alpha  $\n",
    "\n",
    "$\\begin{pmatrix} c_{1} \\\\ c_{0} \\end{pmatrix} \\rightarrow f(z) = c_{1}z - c_{0} \\rightarrow \\frac{c_{0}}{c_{1}} $\n",
    "\n",
    "But what if $\\alpha = \\infty$? We suggested that this should get mapped to the vector $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\n",
    "\n",
    "Interpreted as a monomial this says that $f(z) = 0z - 1 = -1 \\neq 0$. Which has no roots! Indeed, we've reduced the polynomial by a degree: from degree 1 to degree 0. However, it makes a lot of sense to interpret this polynomial as having a root at $\\infty$. For example, if we want to fix the dimension of our vector space to 4, (which is capped at $z^{3}$), what do we do if we have, say, $f(z) = z^{2}$? We should keep track of the missing *higher* terms in some way.\n",
    "\n",
    "So we have a rule: if we lose a degree, we add a root at $\\infty$.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a more systematic way to deal with this. We *homogenize* our polynomial. In other words, we add a second variable so that each term in the resulting two-variable polynomial has the same degree. In this case, we want to do something like:\n",
    "\n",
    "$f(z) = c_{1}z + c_{0} \\rightarrow f(w, z) = c_{1}z + c_{0}w$\n",
    "\n",
    "Suppose we want $f(w, z)$ to have a root $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$. In other words, we want $f(1, 0) = 0$. Then we should pick $f(w, z) = 1z + 0w = z$, which has a root when $z=0$ and $w$ is anything. If we want $f(w, z)$ to have a root $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, aka $f(0, 1) = 0$, then $f(w, z) = 0z + 1w = w$, which has a root when $w=0$ and $z$ is anything. So we have it now that a $z$-root lives at the North Pole, and a $w$-root lives at the South Pole.\n",
    "\n",
    "We also have to consider the sign. If we want $f(w, z)$ to have a root $\\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}$, aka $f(2, 3) = 0$, then we want $f(w, z) = 2z - 3w$, so that $f(2, 3) = 2(3) - 3(2) = 0$. \n",
    "\n",
    "So the correct homogenous polynomial with root $\\begin{pmatrix} c_{1} \\\\ c_{0} \\end{pmatrix}$ is $f(w, z) = c_{1}z - c_{0}w$. Or the other way around, if we have $f(w, z) = c_{1}z + c_{0}w$, then its root will be $\\begin{pmatrix} c_{1} \\\\ -c_{0} \\end{pmatrix}$, up to overall sign.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The representation of a qubit (or spin-$\\frac{1}{2}$ state) as a point on the sphere (plus phase) often goes by the name: the Bloch sphere representation. Using the above construction, we can generalize this into the Majorana sphere, which can represent any spin-$j$ state, not just a spin-$\\frac{1}{2}$ state. \n",
    "\n",
    "If a degree 1 polynomial represents a spin-$\\frac{1}{2}$ state (with a corresponding 2D complex vector), a degree 2 polynomial represents a spin-$1$ state (with a corresponding 3D complex vector), a degree 3 polynomial represents a spin-$\\frac{3}{2}$ state (with a corresponding 4D complex vector), and so on. Considering the roots, instead of the coefficients, this is saying that up to a complex phase, a spin-$\\frac{1}{2}$ state can be identified with point on the sphere, a spin-$1$ state with two points on the sphere, a spin-$\\frac{3}{2}$ state with three points on the sphere. In other words, somewhat magically, we can take a normalized spin-$2j$ state, which lives in $2j+1$ complex dimensions ($4j+2$ real dimensions), and which therefore represents a point on a $(4j+1)$-sphere, as a unique constellation of $2j$ points on the $2$-sphere (plus phase)!\n",
    "\n",
    "And all we're really doing is just finding the roots of a polynomial.\n",
    "\n",
    "This construction is due to Ettore Majorana, and is often known as the \"stellar representation\" of spin, and the points on the sphere are often referred to as \"stars.\" The theory of quantum spin, therefore, becomes in many ways the theory of \"constellations on the sphere.\"\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far example, we could have a degree 2 polynomial. For simplicity, let's consider one that has two roots at $\\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}$. \n",
    "\n",
    "If before we had $f(w,z) = 2z - 3w$, we now want $f(w,z) = (2z - 3w)^2 = (2z - 3w)(2z - 3w) = 4z^2 - 12zw + 9w^2$.\n",
    "\n",
    "If we want a polynomial with two roots at $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, we want $f(w, z) = z^2$. If we want a polynomial with two roots at $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, we want $f(w, z) = w^2$. If we want a polynomial with one root at $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ and one root at $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, we want $f(w, z) = zw$.\n",
    "\n",
    "Indeed, we can use these last three as basis states. Let's take a look:\n",
    "\n",
    "$\n",
    "\\begin{array}{ |c|c|c| } \n",
    " \\hline\n",
    " z^{2} & z & 1 \\\\ \n",
    " \\hline\n",
    " z^{2} & zw & w^{2} & & homogeneous \\ roots & roots \\\\\n",
    " \\hline\n",
    " \\hline\n",
    " 1 & 0 & 0 & \\rightarrow f(w, z) = z^{2} = 0 & \\{ \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\} & \\{ 0, 0 \\}\\\\ \n",
    " 0 & 1 & 0 & \\rightarrow f(w, z) = zw = 0 & \\{\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\} & \\{ 0, \\infty \\}\\\\ \n",
    " 0 & 0 & 1 & \\rightarrow f(w, z) = w^{2} = 0 & \\{ \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\\} & \\{ \\infty, \\infty\\}\\\\\n",
    " \\hline\n",
    "\\end{array}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have three basis states $z^{2}$, $zw$, and $w^{2}$, and they correspond to three constellations, albeit simple ones. The first constellation has two stars at the North Pole. The second has one star at the North Pole and one star at the South Pole. And the third has two stars at the South Pole.\n",
    "\n",
    "Now the interesting fact is that *any 2-star constellation can be written as a complex superposition of these three constellations*. We just add up the three monomials, each weighted by some complex factor, and get a polynomial. The stars are just given by the roots of the homogenous polynomial (or the single variable polynomial with the rule about roots at infinity.)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one more subtlety which we need to take into account in order to be consistent with how the X, Y, Z Pauli operators are defined. The full story is this:\n",
    "\n",
    "If we have a spin state in the usual $\\mid j, m \\rangle$ representation, quantized along the Z-axis, we can express it as a n-dimensional ket, where $n = 2j + 1$. E.g, if j = $\\frac{1}{2}$, the dimension of the representation is 2; for j = $1$, the dimension is 3, and so on.\n",
    "\n",
    "So we have some spin state:\n",
    "$\\begin{pmatrix} a_{0} \\\\ a_{1} \\\\ a_{2} \\\\ \\vdots \\\\ a_{n-1} \\end{pmatrix}$\n",
    "\n",
    "Then the polynomial whose $2j$ roots correspond to the correct stars, taking into account all the secret negative signs, etc, is given by:\n",
    "\n",
    "$p(z) = \\sum_{m=-j}^{m=j} (-1)^{j+m} \\sqrt{\\frac{(2j)!}{(j-m)!(j+m)!}} a_{j+m} z^{j-m}$.\n",
    "\n",
    "$p(z) = \\sum_{i=0}^{i=2j} (-1)^{i} \\sqrt{\\begin{pmatrix} 2j \\\\ i \\end{pmatrix}} a_{i} z^{2j-i}$, where $\\begin{pmatrix} n \\\\ k \\end{pmatrix}$ is the binomial coefficient aka $\\frac{n!}{k!(n-k)!}$.\n",
    "\n",
    "Or homogenously, $p(w, z) = \\sum_{i=0}^{i=2j} (-1)^{i} \\sqrt{\\begin{pmatrix} 2j \\\\ i \\end{pmatrix}} a_{i} z^{2j-i} w^{i}$.\n",
    "\n",
    "This is known as the Majorana polynomial. Why does the binomial coefficient come into play? I'll just note that $\\begin{pmatrix} 2j \\\\ i \\end{pmatrix}$ is the number of groupings of $2j$ roots taken 0 at a time, 1 at a time, 2 at a time, 3 at a time, eventually $2j$ at a time. That's just the number of terms in each of Vieta's formulas, which relate the roots to the coefficients! So when we go from a polynomial $\\rightarrow$ the $\\mid j, m \\rangle$ state, we're normalizing each coefficient by the number of terms that contribute to that coefficient.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Let's check this out using the same type of 3D visualizations we've been using. We'll look at the eigenstates of the X, Y, Z operators for a given spin-$j$. X, Y, Z goes from left to right, and the vertical placement of each sphere is given by its $m$ value. Try changing the $j$ value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qutip as qt\n",
    "import vpython as vp\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "scene = vp.canvas(background=vp.color.white)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# from the south pole\n",
    "def c_xyz(c):\n",
    "        if c == float(\"Inf\"):\n",
    "            return np.array([0,0,-1])\n",
    "        else:\n",
    "            x, y = c.real, c.imag\n",
    "            return np.array([2*x/(1 + x**2 + y**2),\\\n",
    "                             2*y/(1 + x**2 + y**2),\\\n",
    "                   (1-x**2-y**2)/(1 + x**2 + y**2)])\n",
    "\n",
    "# np.roots takes: p[0] * x**n + p[1] * x**(n-1) + ... + p[n-1]*x + p[n]\n",
    "def poly_roots(poly):\n",
    "    head_zeros = 0\n",
    "    for c in poly:\n",
    "        if c == 0:\n",
    "            head_zeros += 1 \n",
    "        else:\n",
    "            break\n",
    "    return [float(\"Inf\")]*head_zeros + [complex(root) for root in np.roots(poly)]\n",
    "\n",
    "def spin_poly(spin):\n",
    "    j = (spin.shape[0]-1)/2.\n",
    "    v = spin\n",
    "    poly = []\n",
    "    for m in np.arange(-j, j+1, 1):\n",
    "        i = int(m+j)\n",
    "        poly.append(v[i]*\\\n",
    "            (((-1)**(i))*np.sqrt(np.math.factorial(2*j)/\\\n",
    "                        (np.math.factorial(j-m)*np.math.factorial(j+m)))))\n",
    "    return poly\n",
    "\n",
    "def spin_XYZ(spin):\n",
    "    return [c_xyz(root) for root in poly_roots(spin_poly(spin))]\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "def display(spin, where):\n",
    "    j = (spin.shape[0]-1)/2\n",
    "    vsphere = vp.sphere(color=vp.color.blue,\\\n",
    "                        opacity=0.5,\\\n",
    "                        pos=where)\n",
    "    vstars = [vp.sphere(emissive=True,\\\n",
    "                        radius=0.3,\\\n",
    "                        pos=vsphere.pos+vp.vector(*xyz))\\\n",
    "                            for i, xyz in enumerate(spin_XYZ(spin.full().T[0]))]\n",
    "    varrow = vp.arrow(pos=vsphere.pos,\\\n",
    "                      axis=vp.vector(qt.expect(qt.jmat(j, 'x'), spin),\\\n",
    "                                     qt.expect(qt.jmat(j, 'y'), spin),\\\n",
    "                                     qt.expect(qt.jmat(j, 'z'), spin)))\n",
    "    return vsphere, vstars, varrow\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "j = 1/2\n",
    "XYZ = {\"X\": qt.jmat(j, 'x'),\\\n",
    "       \"Y\": qt.jmat(j, 'y'),\\\n",
    "       \"Z\": qt.jmat(j, 'z')}\n",
    "for i, o in enumerate([\"X\", \"Y\", \"Z\"]):\n",
    "    L, V = XYZ[o].eigenstates()\n",
    "    for j, v in enumerate(V):\n",
    "        display(v, vp.vector(3*i,3*L[j],0))\n",
    "        spin = v.full().T[0]\n",
    "        print(\"%s(%.2f):\" % (o, L[j]))\n",
    "        print(\"\\t|j, m> = %s\" % spin)\n",
    "        poly_str = \"\".join([\"(%.1f+%.1fi)z^%d + \" % (c.real, c.imag, len(spin)-k-1) for k, c in enumerate(spin_poly(spin))])\n",
    "        print(\"\\tpoly = %s\" % poly_str[:-2])\n",
    "        print(\"\\troots = \")\n",
    "        for root in poly_roots(spin_poly(spin)):\n",
    "            print(\"\\t  %s\" % root)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that the eigenstates of the X, Y, Z operators for a given spin-$j$ representation correspond to constellations with $2j$ stars, and there are $2j+1$ such constellations, one for each eigenstate, and they correspond to the following simple constellations:\n",
    "\n",
    "For example, if $j=\\frac{3}{2}$ and we're interested in the Y eigenstates: 3 stars at Y+, 0 stars at Y-; 2 stars at Y+, 1 stars at Y-; 1 star at Y+, 2 stars at Y-; 0 stars at Y+, 3 stars at Y-.\n",
    "\n",
    "We could choose X, Y, Z or some combination thereof to be the axis we quantize along, but generally we'll choose the Z axis. \n",
    "\n",
    "The remarkable fact is that any constellation of $2j$ stars can be written as a superposition of these basic constellations. We simply find the roots of the corresponding polynomial. And you can check, for instance, that the whole constellation rotates rigidly around the X axis when you evolve the spin state with $e^{iXt}$, for example. (And $e^{Xt}$ corresponds to a boost!) It is fun to watch the constellation evolve under some arbitrary Hamiltonian: the stars swirl around, permuting among themselves, seeming to repel each other like little charged particles.\n",
    "\n",
    "By the way, we haven't yet talked about how to divide polynomials: $\\frac{p(z)}{q(z)}$. And now is a good time since it is intimately related to our X, Y, and Z matrices. If we have some $\\frac{p(z)}{q(z)}$ naturally, their roots will cancel if they can, but beyond that where $q(x)$ has roots, $\\frac{p(x)}{q(x)}$ has *poles*: it goes to $\\infty$ there. We decide this is fine, and we get the idea of a \"rational function,\" like a rational number, but it's a ratio between two polynomials, and it's completely specified by its roots and its poles, and because of the infinities we can regard it as a function *on the sphere*. It turns out that the simplest rational functions are the Mobius transformations: $f(z) = \\frac{az + b}{cz + d}$, where $ad - bc \\neq 0$. Note that $f(\\frac{-d}{c}) = \\infty$ and $f(\\infty) = \\frac{a}{c}$, and if $c=0$, $f(\\infty) = \\infty$. So it's a function on the Riemann sphere, and it consists of: rotations and boosts. The Mobius transformations are conformal, angle preserving transformations, which are 1-to-1 transformations between spheres. And so they are also 1-to-1 transformations of the rational functions themselves, since they are just: two sets of constellations (roots and poles). The higher order rational functions, however, are not 1-to-1.\n",
    "\n",
    "Instead of using the Mobius transformation $f(z)$ acting on $\\mathbb{C} + \\infty$, we can make the $SL(2, \\mathbb{C})$ matrices $\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$ , which, as we know, are generated by the Pauli matrices: X, Y, Z for boosts, and iX, iY, iZ for rotations-- and act on spinors. So there you go.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can display a random spin-$j$ state and evolve it under some random Hamiltonian and watch its constellation evolve. Meanwhile, you can see to the side the Z-basis constellations, and the amplitudes corresponding to them: in other words, the yellow arrows are the components of the spin vector in the Z basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qutip as qt\n",
    "import vpython as vp\n",
    "scene = vp.canvas(background=vp.color.white)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# from the south pole\n",
    "def c_xyz(c):\n",
    "        if c == float(\"Inf\"):\n",
    "            return np.array([0,0,-1])\n",
    "        else:\n",
    "            x, y = c.real, c.imag\n",
    "            return np.array([2*x/(1 + x**2 + y**2),\\\n",
    "                             2*y/(1 + x**2 + y**2),\\\n",
    "                   (1-x**2-y**2)/(1 + x**2 + y**2)])\n",
    "\n",
    "# np.roots takes: p[0] * x**n + p[1] * x**(n-1) + ... + p[n-1]*x + p[n]\n",
    "def poly_roots(poly):\n",
    "    head_zeros = 0\n",
    "    for c in poly:\n",
    "        if c == 0:\n",
    "            head_zeros += 1 \n",
    "        else:\n",
    "            break\n",
    "    return [float(\"Inf\")]*head_zeros + [complex(root) for root in np.roots(poly)]\n",
    "\n",
    "def spin_poly(spin):\n",
    "    j = (spin.shape[0]-1)/2.\n",
    "    v = spin\n",
    "    poly = []\n",
    "    for m in np.arange(-j, j+1, 1):\n",
    "        i = int(m+j)\n",
    "        poly.append(v[i]*\\\n",
    "            (((-1)**(i))*np.sqrt(np.math.factorial(2*j)/\\\n",
    "                        (np.math.factorial(j-m)*np.math.factorial(j+m)))))\n",
    "    return poly\n",
    "\n",
    "def spin_XYZ(spin):\n",
    "    return [c_xyz(root) for root in poly_roots(spin_poly(spin))]\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "def display(spin, where, radius=1):\n",
    "    j = (spin.shape[0]-1)/2\n",
    "    vsphere = vp.sphere(color=vp.color.blue,\\\n",
    "                        opacity=0.5,\\\n",
    "                        radius=radius,\n",
    "                        pos=where)\n",
    "    vstars = [vp.sphere(emissive=True,\\\n",
    "                        radius=radius*0.3,\\\n",
    "                        pos=vsphere.pos+vsphere.radius*vp.vector(*xyz))\\\n",
    "                            for i, xyz in enumerate(spin_XYZ(spin.full().T[0]))]\n",
    "    varrow = vp.arrow(pos=vsphere.pos,\\\n",
    "                      axis=vsphere.radius*vp.vector(qt.expect(qt.jmat(j, 'x'), spin),\\\n",
    "                                                    qt.expect(qt.jmat(j, 'y'), spin),\\\n",
    "                                                    qt.expect(qt.jmat(j, 'z'), spin)))\n",
    "    return vsphere, vstars, varrow\n",
    "\n",
    "def update(spin, vsphere, vstars, varrow):\n",
    "    j = (spin.shape[0]-1)/2\n",
    "    for i, xyz in enumerate(spin_XYZ(spin.full().T[0])):\n",
    "        vstars[i].pos = vsphere.pos+vsphere.radius*vp.vector(*xyz)\n",
    "    varrow.axis = vsphere.radius*vp.vector(qt.expect(qt.jmat(j, 'x'), spin),\\\n",
    "                                           qt.expect(qt.jmat(j, 'y'), spin),\\\n",
    "                                           qt.expect(qt.jmat(j, 'z'), spin))\n",
    "    return vsphere, vstars, varrow\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "j = 3/2\n",
    "n = int(2*j+1)\n",
    "dt = 0.001\n",
    "XYZ = {\"X\": qt.jmat(j, 'x'),\\\n",
    "       \"Y\": qt.jmat(j, 'y'),\\\n",
    "       \"Z\": qt.jmat(j, 'z')}\n",
    "state = qt.rand_ket(n)#qt.basis(n, 0)#\n",
    "H = qt.rand_herm(n)#qt.jmat(j, 'x')#qt.rand_herm(n)#\n",
    "U = (-1j*H*dt).expm()\n",
    "\n",
    "vsphere, vstars, varrow = display(state, vp.vector(0,0,0), radius=2)\n",
    "\n",
    "ZL, ZV = qt.jmat(j, 'z').eigenstates()\n",
    "vamps = []\n",
    "for i, v in enumerate(ZV):\n",
    "    display(v, vp.vector(4, 2*ZL[i], 0), radius=0.5)\n",
    "    amp = state.overlap(v)\n",
    "    vamps.append(vp.arrow(color=vp.color.yellow, pos=vp.vector(3, 2*ZL[i], 0),\\\n",
    "                            axis=vp.vector(amp.real, amp.imag, 0)))\n",
    "\n",
    "T = 100000\n",
    "for t in range(T):\n",
    "    state = U*state\n",
    "    update(state, vsphere, vstars, varrow)\n",
    "    for i, vamp in enumerate(vamps):\n",
    "        amp = state.overlap(ZV[i])\n",
    "        vamp.axis = vp.vector(amp.real, amp.imag, 0)\n",
    "        vp.rate(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting: if the state is an eigenstate of the Hamiltonian, then the constellation doesn't change: there's only a phase evolution. Perturbing the state slightly from that eigenstate will cause the stars to precess around their former locations. Further perturbations will eventually cause the stars to begin to swap places, until eventually it because visually unclear which points they'd been precessing around.\n",
    "\n",
    "Check out [perturb.py](code/perturb.py)! Choose a $j$ value, and it'll show you a random constellation evolving under some random Hamiltonian. We also color the stars and keep track of their paths (which is a little tricky since the roots are in themselves unordered). You can clear the trails with \"c\", toggle them with \"t\". You can stop and start evolving with \"p\", get a new random state with \"i\", and choose a new random Hamiltonian with \"o.\" Use \"e\" to measure the energy: it'll collapse to an energy eigenstate, and you'll see its fixed constellation. The phase is shown as a yellow arrow above. Finally, use \"a/d s/w z/w\" to rotate along the X, Y, and Z directions. Use them to perturb the spin out of its energy eigenstate and watch the stars precess. Precession is what spinning objects like to do, like spinning tops, like the rotating earth whose axis precesses over some 26,000 years, swapping the seasons as it goes.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check our \"group equivariance.\"\n",
    "\n",
    "In other words, we treat our function $f(w, z)$ as a function that takes a spinor/qubit/2d complex projective vector/spin-$\\frac{1}{2}$ state as input. So we'll write $f(\\psi_{little})$, and it's understood that we plug the first component of $\\psi_{little}$ in for $w$ and the second component in for $z$. And we'll say $f(\\psi_{little}) \\Rightarrow \\psi_{big}$, where $\\psi_{big}$ is the corresponding $\\mid j, m \\rangle$ state of our spin-$j$ . If $\\psi_{little}$ is a root, then if we rotate it around some axis, and also rotate $\\psi_{big}$ the same amount around the same axis, then $U_{little}\\psi_{little}$ should be a root of $U_{big}\\psi_{big}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qutip as qt\n",
    "import vpython as vp\n",
    "scene = vp.canvas(background=vp.color.white)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# from the south pole\n",
    "def c_xyz(c):\n",
    "        if c == float(\"Inf\"):\n",
    "            return np.array([0,0,-1])\n",
    "        else:\n",
    "            x, y = c.real, c.imag\n",
    "            return np.array([2*x/(1 + x**2 + y**2),\\\n",
    "                             2*y/(1 + x**2 + y**2),\\\n",
    "                   (1-x**2-y**2)/(1 + x**2 + y**2)])\n",
    "\n",
    "# np.roots takes: p[0] * x**n + p[1] * x**(n-1) + ... + p[n-1]*x + p[n]\n",
    "def poly_roots(poly):\n",
    "    head_zeros = 0\n",
    "    for c in poly:\n",
    "        if c == 0:\n",
    "            head_zeros += 1 \n",
    "        else:\n",
    "            break\n",
    "    return [float(\"Inf\")]*head_zeros + [complex(root) for root in np.roots(poly)]\n",
    "\n",
    "def spin_poly(spin):\n",
    "    j = (spin.shape[0]-1)/2.\n",
    "    v = spin if type(spin) != qt.Qobj else spin.full().T[0]\n",
    "    poly = []\n",
    "    for m in np.arange(-j, j+1, 1):\n",
    "        i = int(m+j)\n",
    "        poly.append(v[i]*\\\n",
    "            (((-1)**(i))*np.sqrt(np.math.factorial(2*j)/\\\n",
    "                        (np.math.factorial(j-m)*np.math.factorial(j+m)))))\n",
    "    return poly\n",
    "\n",
    "def spin_XYZ(spin):\n",
    "    return [c_xyz(root) for root in poly_roots(spin_poly(spin))]\n",
    "\n",
    "def spin_homog(spin):\n",
    "    n = spin.shape[0]\n",
    "    print(\"\".join([\"(%.2f + %.2fi)z^%dw^%d + \" % (c.real, c.imag, n-i-1, i) for i, c in enumerate(spin_poly(spin))])[:-2])\n",
    "    def hom(spinor):\n",
    "        w, z = spinor.full().T[0]\n",
    "        return sum([c*(z**(n-i-1))*(w**(i)) for i, c in enumerate(spin_poly(spin))])\n",
    "    return hom\n",
    "\n",
    "def c_spinor(c):\n",
    "    if c == float('Inf'):\n",
    "        return qt.Qobj(np.array([0,1]))\n",
    "    else:\n",
    "        return qt.Qobj(np.array([1,c])).unit()\n",
    "\n",
    "def spin_spinors(spin):\n",
    "    return [c_spinor(root) for root in poly_roots(spin_poly(spin))]\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "j = 3/2\n",
    "n = int(2*j+1)\n",
    "spin = qt.rand_ket(n)\n",
    "print(spin)\n",
    "h = spin_homog(spin)\n",
    "spinors = spin_spinors(spin)\n",
    "\n",
    "for spinor in spinors:\n",
    "    print(h(spinor))\n",
    "print()\n",
    "\n",
    "dt = 0.5\n",
    "littleX = (-1j*qt.jmat(0.5, 'x')*dt).expm()\n",
    "bigX = (-1j*qt.jmat(j, 'x')*dt).expm()\n",
    "\n",
    "spinors2 = [littleX*spinor for spinor in spinors]\n",
    "spin2 = bigX*spin\n",
    "print(spin2)\n",
    "h2 = spin_homog(spin2)\n",
    "\n",
    "for spinor in spinors2:\n",
    "    print(h2(spinor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Now you might ask what is all this good for?\n",
    "\n",
    "After all, if we really can represent a spin-$j$ state as $2j$ points on the sphere, why not just keep track of those $(x, y, z)$ points and not worry about all these complex vectors and polynomials, etc? Even for the spin-$\\frac{1}{2}$ case, what's the use of working with a two dimensional complex vector representation?\n",
    "\n",
    "And so, now we need to talk about the Stern-Gerlach experiment.\n",
    "\n",
    "Suppose we have a bar magnet. It has a North Pole and a South Pole, and it's oriented along some axis. Let's say you shoot it through a magnetic field that's stronger in one direction, weaker up top, stronger down below. To the extent that the magnet is aligned with or against the magnetic field, it'll be deflected up or deflected down and tilted a little bit. For a big bar magnet, it seems like it can be deflected any continuous amount, depending on the original orientation of the magnet.\n",
    "\n",
    "But what makes a bar magnet magnetic? We know that moving charges produce a magnetic field, so we might imagine that there is something \"circulating\" within the bar magnet.\n",
    "\n",
    "What happens if we start dividing the bar magnet into pieces? We divide it in two: now we have two smaller bar magnets, each with their own pole. We keep dividing. Eventually, we reach the \"atoms\" themselves whose electrons are spin-$\\frac{1}{2}$ particles, which means they're spinning, and this generates a little magnetic field: to wit, a spin-$\\frac{1}{2}$ particle is like the tiniest possible bar magnet. It turns out that what makes a big bar magnet magnetic is that all of its spins are entangled so that they're all pointing in the same direction, leading to a macroscopic magnetic field.\n",
    "\n",
    "Okay, so what happens if we shoot a spin-$\\frac{1}{2}$ particle through the magnetic field?\n",
    "\n",
    "Here's the surprising thing. It is deflected up or down by some fixed amount, with a certain probability, and if it is deflected up, then it ends up spinning perfectly aligned with the magnetic field; and if it is deflected down, then it ends up spinning perfectly anti-aligned with the magnetic field. There's only two outcomes.\n",
    "\n",
    "![](img/stern_gerlach1.jpg)\n",
    "\n",
    "The experiment was originally done with silver atoms which are big neutral atoms with a single unpaired electron in their outer shells. In fact, here's the original photographic plate.\n",
    "\n",
    "![](img/stern_gerlach2.jpg)\n",
    "\n",
    "This was one of the crucial experiments that established quantum mechanics. It was conceived in 1921 and performed in 1922. The message is that spin angular momentum isn't \"continuous\" when you go to measure it; it comes in discrete quantized amounts.\n",
    "\n",
    "To wit, suppose your magnetic field is oriented along the Z-axis. If you have a spin-$\\frac{1}{2}$ state $\\begin{pmatrix} a \\\\ b \\end{pmatrix}$ represented in the Z-basis, then the probability that the spin will end up in the $\\mid \\uparrow \\rangle$ state is $aa*$ and the probability that the spin will end up in the $\\mid \\downarrow \\rangle$ state is given by $bb^{*}$. This is of course if we've normalized our state so that $aa^{*} + bb^{*} = 1$, which of course we always can.\n",
    "\n",
    "What if we measured the spin along the Y-axis? Or the X-axis? Or any axis? We'd express the vector $\\begin{pmatrix} a \\\\ b \\end{pmatrix}$ in terms of the eigenstates of the Y operator or the X operator, etc. We'd get another vector $\\begin{pmatrix} c \\\\ d \\end{pmatrix}$ and $cc^{*}$ would be the probability of getting $\\uparrow$ in the Y direction and $dd^{*}$ would be the probability of getting $\\downarrow$ in the Y direction.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For spin-$\\frac{1}{2}$ there is an easy way to think about where these probabilities come from geometrically.\n",
    "\n",
    "![](img/spin_probability.jpg)\n",
    "\n",
    "The eigenstates of a 2x2 Hermitian matrix correspond to orthogonal complex vectors, but antipodal points on the sphere: so they define an axis: this is the axis you're measuring along, the axis of the magnetic field in the Stern-Gerlach set-up. Now given a point on the sphere representing spin-$\\frac{1}{2}$ particle's spin axis, you project that point perpendicularly onto the measurement axis. This divides that line segment into two pieces. If you imagine that the line is like an elastic band that snaps randomly at some location, and then the two ends are dragged to the two antipodal points, carrying our projected point with it, then the projected point will end up at one or other of the two antipodes with a certain probability, which is indeed the correct probability for that experiment. Note that this simple geometric picture only works for spin-$\\frac{1}{2}$; the generalization to higher spin isn't so easily visualizable, but is basically analogous.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we send a spin-$1$ particle through the machine?\n",
    "\n",
    "![](img/stern_gerlach3.jpg)\n",
    "\n",
    "The particle ends up in one of three locations, and its spin will be in one of the three eigenstates of the operator in question, each with some probability. Recall the eigenstates correspond to: two points at the North pole; one point at North Pole, one point at South Pole; two points at South Pole. So if we're in the Z-basis we have some $\\begin{pmatrix} a \\\\ b \\\\ c \\end{pmatrix}$ and the probability of the first outcome is $aa^{*}$, the second outcome is $bb^{*}$, and the third outcome is $cc^{*}$.\n",
    "\n",
    "And in general, a spin-$j$ particle sent through a Stern-Gerlach set-up will end up in one of $2j+1$ locations, each correlated with one of the $2j+1$ eigenstates of the spin-operator in that direction.\n",
    "\n",
    "The idea is that a big bar magnet can be treated as practically a spin-$\\infty$ particle, with an infinite number of stars at the same point. And so, it \"splits into so many beams\" (and is being so massively decohered as it goes along), that it seems to end up in a continuum of possible state and locations. Thus it took so many thousands of years before we realized that (spin) angular momentum is actually quantized.\n",
    "\n",
    "Below is a simple version of a Stern-Gerlach set-up. We make some simplifications. We work in 2D. The particle starts to the left and zips along horizontally to the right. The magnetic field (Z direction) is up/down. The particle's Z operator couples to its position along the Z axis. And the magnetic field acts on the spin. Finally, we make a finite approximation which is effectively like putting the particle in a box, so after a while it starts reflecting off the edges. In any case, the probability of the particle to be at a given location is visualized as the radius of the sphere shown at that point. Try changing the particles $j$-value, its initial state, and even the number of lattice spacings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qutip as qt\n",
    "import vpython as vp\n",
    "\n",
    "vp.scene.background = vp.color.white\n",
    "\n",
    "dt = 0.001\n",
    "n = 5\n",
    "spinj = 0.5\n",
    "spinn = int(2*spinj+1)\n",
    "\n",
    "S = {\"X\": qt.tensor(qt.identity(n), qt.identity(n), qt.jmat(spinj, 'x')/spinj),\\\n",
    "     \"Y\": qt.tensor(qt.identity(n), qt.identity(n), qt.jmat(spinj, 'y')/spinj),\\\n",
    "     \"Z\": qt.tensor(qt.identity(n), qt.identity(n), qt.jmat(spinj, 'z')/spinj)}\n",
    "\n",
    "P = {\"X\": qt.tensor(qt.momentum(n), qt.identity(n), qt.identity(spinn)),\\\n",
    "     \"Z\": qt.tensor(qt.identity(n), qt.momentum(n), qt.identity(spinn))}\n",
    "\n",
    "B = np.array([0, 0, -1])\n",
    "H = (P[\"X\"]*P[\"X\"] + P[\"Z\"]*S[\"Z\"]) + \\\n",
    "        sum([B[i]*S[o] for i, o in enumerate(S)])\n",
    "U = (-1j*dt*H).expm()\n",
    "\n",
    "Q = qt.position(n)\n",
    "Ql, Qv = Q.eigenstates()\n",
    "zero_index = -1\n",
    "for i, l in enumerate(Ql):\n",
    "    if np.isclose(l, 0):\n",
    "        zero_index = i\n",
    "\n",
    "initial = qt.tensor(Qv[0], Qv[zero_index], qt.basis(2, 0))\n",
    "state = initial.copy()\n",
    "\n",
    "vspheres = [[vp.sphere(color=vp.color.blue,\\\n",
    "                        radius=0.5, opacity=0.3,\\\n",
    "                        pos=vp.vector(Ql[i], Ql[j], 0))\\\n",
    "                for j in range(n)] for i in range(n)]\n",
    "varrows = [[vp.arrow(pos=vspheres[i][j].pos,\\\n",
    "                      axis=vp.vector(0,0,0))\\\n",
    "                 for j in range(n)] for i in range(n)]\n",
    "\n",
    "Qproj = [[qt.tensor(qt.tensor(Qv[i], Qv[j])*qt.tensor(Qv[i], Qv[j]).dag(), qt.identity(spinn))\\\n",
    "              for j in range(n)] for i in range(n)]\n",
    "\n",
    "evolving = True\n",
    "def keyboard(event):\n",
    "    global evolving\n",
    "    key = event.key\n",
    "    if key == \"q\":\n",
    "        evolving = False if evolving else True\n",
    "#vp.scene.bind('keydown', keyboard)\n",
    "\n",
    "while True:\n",
    "    if evolving:\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                vspheres[i][j].radius = qt.expect(Qproj[i][j], state)\n",
    "                proj_state = Qproj[i][j]*state\n",
    "                axis = [qt.expect(S[o], proj_state) for i, o in enumerate([\"X\", \"Z\"])]\n",
    "                varrows[i][j].axis = vp.vector(axis[0], axis[1], 0)\n",
    "                vp.rate(2000)\n",
    "        state = U*state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Okay, so let's take a moment to stop and think.\n",
    "\n",
    "If we wanted to be fancy, we could describe a point on a plane $(x, y)$ as being in a \"superposition\" of $(1,0)$ and $(0,1)$. For example, the point $(1,1)$ which makes a diagonal line from the origin would be an equal superposition of being \"horizontal\" and \"vertical.\" In other words, we can add locations up and the sum of two locations is also a location. \n",
    "\n",
    "It's clear that we can describe a point on the plane in many different ways. We could rotate our coordinate system, use any set of two linearly independent vectors in the plane, and write out coordinates for the same point using many different frames of reference. This doesn't have anything to do with the point. The point is where it is. But we could describe it in many, many different ways as different superpositions of different basis states. Nothing weird about that. They just correspond to \"different perspectives\" on that point.\n",
    "\n",
    "Another example of superposition, in fact, the ur-example, if you will, is waves. You drop a rock in the water and the water starts rippling outwards. Okay. You wait until the water is calm again, and then you drop another rock in the water at a nearby location and the water ripples outwards, etc. Now suppose you dropped both rocks in at the same time. How will the water ripple? It's just a simple sum of the first two cases. The resulting ripples will be a  sum of the waves from the one rock and the waves from the other rock. In other words, you can superpose waves, and that just makes another wave. This works for waves in water, sound waves, even light waves. (And by the way, it's true for *forces* in Newtonian mechanics as well.)\n",
    "\n",
    "Waves are described by differential equations. And solutions to (homogenous) differential equations have the property that a sum of two solutions is also a solution.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, suppose we have a simple ordinary differential equation $y'' + 2y' + y = 0$. The idea is to find some function $y(x)$ such that the sum of its second derivative plus two times its first derivative plus the function equals 0. Suppose we had such a function. And what if we had another function $z(x)$ such that $z'' + 2z' + z = 0$, in other words, $z(x)$ is also a solution to the differential equation. If we took any linear combination of $y$ and $z$ then that will also be a solution.\n",
    "\n",
    "E.g:\n",
    "\n",
    "$y'' + 2y' + y = 0$\n",
    "\n",
    "$z'' + 2z' + z = 0$\n",
    "\n",
    "$(y+z)'' + 2(y+z)' + (y+z) = y'' + z'' + 2y' + 2z' + y + z = (y'' + 2y' + y) + (z'' + 2z' + z) = 0 + 0 = 0 $\n",
    "\n",
    "This works because taking the derivative is a linear operator! So that $(y + z)' = y' + z'$.\n",
    "\n",
    "Without going greatly into details here, we can find a general solution to the different equation using an auxilliary polynomial.\n",
    "\n",
    "$y'' + 2y' + y = 0 \\rightarrow k^{2} + 2k + 1 = 0 \\rightarrow (k + 1)(k + 1) = 0 \\rightarrow k = \\{-1,-1\\}$\n",
    "\n",
    "So that the general solution is $y = c_{0}e^{-x} + c_{1}xe^{-x}$. It doesn't matter the whole theory of how I solved this equation. You can confirm that it works:\n",
    "\n",
    "$y' = -c_{0}e^{-x} + c_{1}(-xe^{-x} + e^{-x})$\n",
    "\n",
    "$y'' = c_{0}e^{-x} + c_{1}(xe^{-x} - e^{-x} - e^{-x})$\n",
    "\n",
    "$ y'' + 2y' + y = (c_{0}e^{-x} + c_{1}xe^{-x} - c_{1}e^{-x} - c_{1}e^{-x}) + 2(-c_{0}e^{-x} - c_{1}xe^{-x} + c_{1}e^{-x}) + (c_{0}e^{-x} + c_{1}xe^{-x}) = 2c_{0}e^{-x} - 2c_{0}e^{-x} + 2c_{1}xe^{-x} - 2c_{1}e^{-x} + 2c_{1}e^{-x} - 2c_{1}e^{-x} = 0 $\n",
    "\n",
    "The point is that the solutions form a 2D vector space and any solution can be written as a linear combination of $e^{-x}$ and $xe^{-x}$. In other words, I can plug any scalars in for $c_{0}$ and $c_{1}$ and I'll still get a solution.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen the same thing happen in terms of our constellations. We can take any two constellations (with the same number of stars) and add them together, and we always get a third constellation. Moreover, any given constellation can be expressed in a multitude of ways, as a complex linear combination of (linearly independent) constellations.\n",
    "\n",
    "We could take one and the same constellation and express it as a complex linear superposition of X eigenstates, Y eigenstates, or the eigenstates of *any* Hermitian operator. The nice thing about Hermitian operators is that their eigenvectors are all orthogonal, and so we can use them as a basis.\n",
    "\n",
    "In other words, the constellation can be described in different reference frames in different ways, as a superposition of different basis constellations.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the daring thing about quantum mechanics is that it says that basically: everything is just like waves. If you have one state of a physical system and another state of a physical system, then if you add them up, you get another state of the physical system. In theory, everything obeys the superposition principle!\n",
    "\n",
    "There is something mysterious about this, but not in the way it's usually framed. Considering a spin-$\\frac{1}{2}$ particle, it seems bizarre to say that its quantum state is a linear superposition of being $\\uparrow$ and $\\downarrow$ along the Z axis. But we've seen that it's not bizarre at all! Any point on the sphere can be written as linear superposition of $\\uparrow$ and $\\downarrow$ along some axis! So that you really can imagine that the spin is definitely just spinning around some definite axis, given by a point on the sphere. But when you go to measure it, you pick out a certain special axis: the axis you're measuring along. You can express that point on the sphere as a linear combination of $\\uparrow$ and $\\downarrow$ along that axis, and then $aa*$ and $bb*$ give you the probabilities that you get either the one or the other outcome.\n",
    "\n",
    "In other words, the particle may be spinning totally concretely around some axis, but when you go to measure it, you just get one outcome or the other with a certain probability. You can only reconstruct what that axis must have been before you measured it by preparing lots of such particles in the same state, and measuring them all in order to empirically determine the probabilities. In fact, to nail down the state you have to calculate (given some choice of X, Y and Z) $(\\langle \\psi \\mid X \\mid \\psi \\rangle, \\langle \\psi \\mid Y \\mid \\psi \\rangle, \\langle \\psi \\mid Z \\mid \\psi \\rangle)$, in other words, you have to do the experiement a bunch of times measuring the (identically prepared) particles along three orthogonal axes, and get the proportions of outcomes in each of those cases, weight those probabilities by the eigenvalues of X, Y, Z, and then you'll get the $(x, y, z)$ coordinate of the spin's axis.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yeah, we could just represent our spin-$j$ state as a set of $(x, y, z)$ points on the sphere. But it's better to use a *unitary* representation, a representation as a complex vector with unit norm, because then we can describe the constellation as a superposition of *outcomes of an experimental situation* where the components of the vector have the interpretation of *probability amplitudes* whose \"squares\" give the probability for that outcome.\n",
    "\n",
    "In other words, quantum mechanics effects a radical generalization of the idea of a perspective shift or reference frame. We normally think of a reference frame as provided by three orthogonal axis in 3D, say, by my thumb, pointer finger, and middle finger splayed out. In quantum mechanics, the idea is that *an experimental situation* provides a reference frame in the form of a Hermitian operator--an *observable*--whose eigenstates provide \"axes\" along which we can decompose the state of system, even as they correspond to *possible outcomes to the experiment*. The projection of the state onto each of these axes gives the probability (amplitude) of that outcome.\n",
    "\n",
    "It's an amazing twist on the positivist idea of describing everything as a black box: some things go in, some things come out, and you look at the probabilities of the outcomes, and anything else one must pass over in silence. And that's all one can hope for. In the spin case, we can see that it can be fully characterized by experiemental outcomes, but with a twist: the spin state is a superposition of \"possible outcomes to an experiment,\" which at first seems metaphysically bizarre, but it can be interpreted geometrically as: a perfectly concrete constellation on the sphere. \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dirac writes in his Principles of Quantum Mechanics, \"[QM] requires us to assume that ... whenever the system is definitely in one state we can consider it as being partly in each of two or more other states. The original state must be regarded as the result of a kind of superposition of the two or more new states, in a way that cannot be conceived on classical ideas.\"\n",
    "\n",
    "Around the same time, Schrodinger proposed his cat as a kind of reductio ad absurdum to the universal applicability of quantum ideas. He asks us to consider whether a cat can be in a superposition of $\\mid alive \\rangle \\ + \\mid dead \\rangle$. Such a superposition seems quite magical if we're considering a cat. How can a cat be both alive and dead? And yet, the analogous question for a spin isn't mysterious at all. How can a spin be in a superposition of $\\mid \\uparrow \\rangle \\ + \\mid \\downarrow \\rangle$ (in the Z basis)? Easily! It's just pointed in the X+ direction! The analogous thing for a cat would be something like $\\mid alive \\rangle \\ + \\mid dead \\rangle = \\mid sick? \\rangle$--I don't propose that seriously, other than to emphasize that what the superposition principle is saying is that superpositions of states *really should be perfectly good comprehensible states of the system as well*.\n",
    "\n",
    "In the case of a quantum spin, we can see that we can regard the spin's constellation as being perfectly definite, but describable from many different reference frames, different linearly independent sets of constellations. Which reference frame you use is quite irrelevant to the constellation, of course, until you go to measure it, and then the spin ends up in one of the reference states with a certain probability. So the mystery isn't superposition per se; it has something to do with measurement. (You might ask how this plays out in non-spin cases, for example, superpositions of position: one clue comes when we start discussing spin and oscillator coherent states. In any case, it's important to keep in mind that there may be a certain specialness about the case of quantum spin, but precisely because of that, it can help guide our thinking.) \n",
    "\n",
    "You might ask: Doesn't the *actual* Hamiltonian fix a basis, the energy basis? Sure, but the Hamiltonian can change. The deeper question is: If we prepare a spin in some superposition of Z eigenstates (by measuring it in the X direction, say), we can regard it as definitely having a certain constellation. But implicitly, since we prepared the spin, we and the particle both agree about what we mean by the X, Y, Z axes. This is implicit in our ability to even represent the particle's state relative to a common set of directions. But what if we hadn't done that? What if we didn't necessarily have any shared reference frame between us? Are we allowed to still say that the particle as a \"definite constellation\"? We return to these questions later on when we briefly discuss spin networks.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what's going on with these measurements, with their apparently \"random\" outcomes? Opinions differ, but one analogy I like is the idea of a \"forced choice question.\" I show you a picture of a diagonal line and I ask you: Is it a vertical line or a horizontal line? And you're like: It's both! It's equal parts vertical and horizontal! That's what it *means* to be diagonal; how can I choose between them? I have as many reasons to choose vertical as horizontal. If the line were inclined a little to the horizontal, then maybe I'd be inclined to say one or the other, although not by much! But suppose I *force* you to choose. You have to pick one! What do you do? You have to make a choice, but there is literally no reason for you to choose one or the other, in the sense that you have as many reasons to choose horizontal as to choose vertical. And so, you have to choose randomly. \n",
    "\n",
    "It's the same with the spin. Suppose it's spinning in the X+ direction. And I ask it, Are you up or down along the Z axis? Well, both! But the experimental situation forces the particle to give some answer, and it has as many reasons to choose the one as the other, and so it just... picks one! In other words, this is the ultimate origin for quantum indeterminism: you've forced a physical system to make a choice, but it has no reason to choose: and so, it just decides for itself. It's like: you ask a stupid question, you get a stupid answer.\n",
    "\n",
    "There's a old folktale from the Middle Ages called Buridan's Ass or the Philosopher's Donkey. The old donkey has been ridden hard by the philosopher all day, and by evening, it's both hungry and thirsty. The philosopher (being, who knows, perhaps in an experimental mindset) lays out a bucket of water and a bucket of oats before the donkey. The donkey is really hungry, so it wants to go for the oats, but it's also really thirsty, so it wants to go for the water. In fact, it's just as hungry as it is thirsty. It has to pick oats or water to dig into first, but it has as many reasons to pick the oats first as the water first, and so it looks back and forth and back and forth, and can't decide, and eventually passes out, steam coming out of its ears.\n",
    "\n",
    "The philosopher Leibniz later articulated something called the Principle of Sufficient Reason, which was once very popular, and it basically said that: everything happens for a reason. The donkey exposes the consequence of this idea. If everything has to happen for a reason, and the donkey has as many reasons to choose the water as the oats, then the donkey can't do anything, since there would be no reason for choosing one over the other. And so, the donkey keels over--for what reason? It had as many reasons to choose the water as the oats.\n",
    "\n",
    "Quantum mechanics strongly suggests that the Principle of Sufficient Reason is false. Nature, as it were, cuts the Gordian knot of the philosopher. An X+ spin presented with a bucket of $\\uparrow$ and a bucket of $\\downarrow$ doesn't glitch out, even though it has as many reasons to choose the one as the other. Instead: it just fucking picks one, for no reason at all. It decides all on its own without any help from \"reasons.\" \n",
    "\n",
    "If the spin had been in the Z+ state, of course, and we asked $\\uparrow$ or $\\downarrow$ along the Z axis, then it would answer up with certainty, and vice versa for Z-.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A further point. A spin state can be described from many points of view, each corresponding to some \"observable,\" some experimental situation, which, as it were, provides a filter, separating out one outcome from another. We can also think about this in terms of entanglement. In the Stern-Gerlach experiment, after all, we actually measure the *position* of the particle, which has become entangled with the spin, so that if the particle is deflected up, it's spin is $\\uparrow$ and if it's deflected down, it's spin is $\\downarrow$. So that even though the particle in itself can be described equally well from any reference frame, the entanglement between the particle's spin and its position provides a particular reference frame, in that an (arbitrary) collection of basis states for the particle's spin have been paired with an (arbitrary) collection of basis states for the particle's position, such that there will now be a dependency between the outcomes to experiments on either of them. If the particle is measured to be here, then its spin will be $\\uparrow$. If the particle is measured to be there, then its spin will be $\\downarrow$--and vice versa. \n",
    "\n",
    "So although the reference frame by which we describe something is arbitrary, things can get entangled, which pairs basis states of the one with basis states of the other, so that each pairing of basis states now has its own probability, and the pairs are all in superposition, leading to correlations between the outcomes of experiments done on the two things. The entanglement can be seen as a \"shared reference frame\" between the spin and the position.\n",
    "\n",
    "So that, while in its own terms the spin may have its constellation, the spin *interfaces with the world* via some decomposition of that constellation into a superposition over \"experimental outcomes\" (which are constellations themselves), which can get entangled with other outcome states of other systems. So that the in itself arbitrary decomposition of the constellation into basis constellations provides the hooks by which the spin becomes correlated with the rest of the world.\n",
    "\n",
    "Let us return for a moment to the lowly pebble. If at first, to communicate with a pebble, we had to agree on whether an absence or a presence was significant, then on where to start counting, and then where 0 was, and then what rational number translated between our different notions of \"1\", and then a complex number to rotate from my axis to your axis, now we need to specify the basis vectors in terms of which we've written our \"polynomial.\" This could mean: the 3D coordinate frame for some $(x, y, z)$ point, but in the general case, the basis vectors are bundled into a Hermitian matrix representing a quantum observable, so that to specify the basis vectors is to: specify which experiment you did. To wit, I do the Stern-Gerlach experiment, and I put a pebble in pile A if I got $\\uparrow$, and a pebble in pile B if I got $\\downarrow$. In order to successfully communicate to you what I mean by those pebbles, I have to specify: what experiment provided the reference frame for those outcomes, and which eigenvalue/eigenvector pair the pebble corresponds to. Then we can both compute the proportions between the outcomes, and reconstruct the state of the physical system, and we three will all be in agreement about what we're talking about.\n",
    "\n",
    "We can view these Hermitian matrices are providing a kind of \"measure\" for states, each associated, so to speak, with a certain \"modality.\" $\\langle\\psi\\mid H \\mid \\psi\\rangle$ gives the expectation value of the operator $H$ on the state $\\psi$: it’s a sum over the eigenstates of H, with the probabilities $\\mid \\langle \\psi \\mid h_{n} \\rangle \\mid^{2}$ for each eigenvector $h_{n}$ weighting the corresponding eigenvalue $\\lambda_{n}$ of H. The expectation value is real because the eigenvalues of a self-adjoint operator are real, and the eigenvalues represent the possible numerical outcomes of an individual experiment: the energy value, the position value, etc. (Of course the semantics of a given Hermitian matrix is determined by its relation to other Hermitian matrices, its algebraic properties, the way it might represent the generator of a symmetry group operation, for example. For indeed, the power of matrices is that their multiplication rule is non-commutative: for these \"numbers,\" (which following our overarching scheme, provide context for polynomials), it's quite possible that $AB \\neq BA$. And so they can furnish \"representations\" of a great many symmetry groups, infinite or otherwise, which themselves, by the way, can be \"broken down\" as composites of \"prime\" or \"simple groups,\" and which theory, by the by the way, originated in the study of the symmetry groups of the roots of polynomials. This is Galois theory, a famous result of which is this. The symmetry group of the roots is determined by listening out all algebraic relationships between the roots with rational coefficients (like $AB = 1$, $A + D = 0$, etc), and looking at all the ways you can swap the roots in those expressions that leaves them true. These swaps form a symmetry group. If that group can be decomposed into \"cyclic groups\" aka the symmetry groups corresponding to each set of n roots of unity (complex numbers forming the vertices of an n-gon), then that polynomial is solvable: there's the equivalent of a \"quadratic formula,\" an expression involving only integers and addition/subtraction/multiplication/division/exponentiation/root-taking, where you plug in the coefficients, and out pop the roots. Otherwise you have to approximate the roots of the polynomial! And a consequence is that quintic polynomials generally speaking have more than cyclic symmetry, but polynomials up to degree 4 are all solvable. End sidebar.)\n",
    "\n",
    "We could imagine $H$ to be a kind of “ruler” which we are using to measure $\\psi$. Using the standard metric, $\\langle \\psi \\mid \\psi \\rangle$, the length of $\\psi$ is 1: this corresponds to the probability interpretation. But under the $H$ metric, the length of $\\psi$ is different: it's $\\langle\\psi\\mid H \\mid \\psi\\rangle$. So all the different Hermitian matrices correspond to different ways of evaluating the length of the state vector, which correspond to different physical situations and consequently different interpretations of the state vector. For example, if we use the Hamiltonian of the system as the “metric,” the length of the vector $\\psi$ corresponds to the average energy. If we use the position operator, the length of the vector $\\psi$ corresponds to the average position. And so on for momentum, angular momentum, etc, any operator. But the “standard metric” corresponds to the probability interpretation, which undergirds them all.\n",
    "\n",
    "And while you're thinking about that recall that time evolution in quantum mechanics involves exponentiating the observables, and that observables that commute with the Hamiltonian are conserved in time.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last comment. Just as polynomials give context to their roots, a matrix gives context to polynomials. In fact, in some sense, a matrix *is* a polynomial, but possibly distorted in perspective. Here's a nice way of seeing that. \n",
    "\n",
    "Consider how we find the eigenvectors of a matrix. We'll stick to the finite dimensional 2x2 case.\n",
    "\n",
    "If we have, $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$, we want:\n",
    "\n",
    "$ A\\vec{v} = \\lambda\\vec{v}$\n",
    "\n",
    "$ A\\vec{v} - \\lambda\\vec{v} = 0$\n",
    "\n",
    "$ (A - \\lambda I)\\vec{v} = 0$\n",
    "\n",
    "So that:\n",
    "\n",
    "$\\begin{pmatrix} a - \\lambda & b \\\\ c & d - \\lambda \\end{pmatrix} \\begin{pmatrix} v_{0} \\\\ v_{1} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$\n",
    "\n",
    "Therefore, $\\begin{pmatrix} a - \\lambda & b \\\\ c & d - \\lambda \\end{pmatrix}$ shouldn't be invertible: since it has to send $\\vec{v}$ to the 0 vector. \n",
    "\n",
    "A matrix is not invertible if its determinant is 0. So we want:\n",
    "\n",
    "$\\begin{vmatrix} a - \\lambda & b \\\\ c & d - \\lambda \\end{vmatrix} = 0$\n",
    "\n",
    "So that: $ (a - \\lambda)(d - \\lambda) - (b)(c) = 0 $, or:\n",
    "\n",
    "$ ad - a\\lambda -d\\lambda + \\lambda^{2} - bc = 0$, or:\n",
    "\n",
    "$ \\lambda^{2} - (a + d)\\lambda + (ad - bc) = 0$\n",
    "\n",
    "So the eigenvalues are the roots of this polynomial. \n",
    "\n",
    "We can express our matrix in another basis with a change-of-basis transformation:\n",
    "\n",
    "$A^{\\prime} = U^{-1}A U$.\n",
    "\n",
    "We'll find that $A^{\\prime}$ has exactly the same eigenvalues. They are invariant under basis transformations. Since the trace is the sum of the eigenvalues, and the determinant is the product of the eigenvalues, they too are left the same. Indeed, if the matrix has a complete set of eigenvectors, than we can always bring it to *diagonal form*, a matrix of all 0's, with the eigenvalues along the diagonal. \n",
    "\n",
    "So we can think about the matrix as *really just being* just a polynomial, which defines some roots, which are the eigenvalues. But the matrix representation keeps track of the fact that we may be viewing the polynomial in a different basis.\n",
    "\n",
    "In quantum mechanics, two observables are \"simultaneously measurable\" if their Hermitian matrices can be simultaneously diagonalized. \n",
    "\n",
    "By the way, if you think about it, in section 5, we invented the complex number (to give context to the rationals). Now in section 6, we're considering multiple complex numbers, so we invented the polynomial to give context to its roots. So really, in the *next* section, we should invent the matrix to switch between perspectives on multiple polynomials. But it's no fun talking about vector spaces without linear operators on them, so here we are.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to spin.\n",
    "\n",
    "I keep emphasizing that a spin really does have this constellation associated with it. But do we ever observe the \"stars\" themselves? Well, not exactly: we can reconstruct the quantum state of the spin via a buch of measurements on identically prepared systems, and then: express it in the Z-basis (for example), and find the roots of the polynomial. But they really are there, as the following argument suggests.\n",
    "\n",
    "A \"spin coherent state\" is a state where all the stars are in the same location. The \"coherent states\" are like the \"most classical states.\" In the infinite dimensional case, you could define them as eigenstates of the annihilation operator--in other words, you remove a quantum and it doesn't make a difference.  We'll return to this idea in a moment. In the finite dimensional spin case, if you had a spin-$j$ state, then the coherent states would be all the states with $2j$ stars in the same location. They have very interesting properties. For example, any set of $2j+1$ coherent states (each with $2j$ coincident stars) forms a linearly independent (but not necessarily orthogonal) basis for the spin-$j$ Hilbert space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qutip as qt\n",
    "import itertools\n",
    "\n",
    "def xyz_c(xyz):\n",
    "    x, y, z = xyz\n",
    "    if np.isclose(z,-1):\n",
    "        return float(\"Inf\")\n",
    "    else:\n",
    "        return x/(1+z) + 1j*y/(1+z)\n",
    "\n",
    "def roots_coeffs(roots):\n",
    "    n = len(roots)\n",
    "    coeffs = np.array([((-1)**(-i))*sum([np.prod(term) for term in itertools.combinations(roots, i)]) for i in range(0, len(roots)+1)])\n",
    "    return coeffs/coeffs[0]\n",
    "\n",
    "def roots_poly(roots):\n",
    "    zeros = roots.count(0j)\n",
    "    if zeros == len(roots):\n",
    "        return [1j] + [0j]*len(roots)\n",
    "    poles = roots.count(float(\"Inf\"))\n",
    "    roots = [root for root in roots if root != float('Inf')]\n",
    "    if len(roots) == 0:\n",
    "        return [0j]*poles + [1j]\n",
    "    return [0j]*poles + roots_coeffs(roots).tolist()\n",
    "\n",
    "def poly_spin(poly):\n",
    "    j = (len(poly)-1)/2.\n",
    "    spin = []\n",
    "    for m in np.arange(-j, j+1):\n",
    "        i = int(m+j)\n",
    "        spin.append(poly[i]/\\\n",
    "            (((-1)**(i))*np.sqrt(np.math.factorial(2*j)/\\\n",
    "                        (np.math.factorial(j-m)*np.math.factorial(j+m)))))\n",
    "    aspin = np.array(spin)\n",
    "    return aspin/np.linalg.norm(aspin)\n",
    "\n",
    "def XYZ_spin(XYZ):\n",
    "    return qt.Qobj(poly_spin(roots_poly([xyz_c(xyz) for xyz in XYZ])))\n",
    "\n",
    "def spinor_xyz(spinor):\n",
    "    if isinstance(spinor, np.ndarray):\n",
    "        spinor = qt.Qobj(spinor)\n",
    "    return np.array([qt.expect(qt.sigmax(), spinor),\\\n",
    "                     qt.expect(qt.sigmay(), spinor),\\\n",
    "                     qt.expect(qt.sigmaz(), spinor)])\n",
    "\n",
    "############################################################################\n",
    "\n",
    "j = 3/2\n",
    "n = int(2*j+1)\n",
    "M = np.array([XYZ_spin([spinor_xyz(qt.rand_ket(2))]*(n-1)).full().T[0] for i in range(n)]).T\n",
    "print(\"%s != 0\" % np.linalg.det(M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice result is that, given two spin coherent states pointing in directions $n_{1}$ and $n_{2}$ (where these are (x, y, z) coordinates), then:\n",
    "\n",
    "$\\mid \\langle n_{1} \\mid n_{2} \\rangle \\mid^{2} = (\\frac{1+ n_{1} \\cdot n_{2}}{2})^{2j}$.\n",
    "\n",
    "Furthermore, the spin coherent states define a resolution of the identity. In other words, they form an (overcomplete) basis. For a given $j$, define the spin coherent state (of $2j$ stars) at a given location on the sphere in terms of spherical coordinates $\\theta$ and $\\phi$: $\\mid \\theta, \\phi \\rangle$. Then:\n",
    "\n",
    "$\\int \\mid \\theta, \\phi \\rangle \\langle \\theta, \\phi \\mid d\\mu(\\theta, \\phi) = \\mathbb{1}$, where $d\\mu(\\theta, \\phi) = \\frac{2j+1}{4\\pi}sin(\\theta)d\\theta d\\phi$\n",
    "\n",
    "(An aside: in a previous adventure, we talked about one qubit steering another qubit. We went through all the points on the sphere of qubit A, projected A into those states, and looked to see where B was steered to in turn. This was in the context of a spin-$\\frac{1}{2}$. But we can see it kinda works for higher spin too: we just go through all the points on the sphere of spin A, and project A into the *spin coherent state of $2j$ stars at that point*, and see where B is steered to (which of course might be some arbitrary constellation). Since going over the whole sphere exhausts the states of A, this can completely characterize the entanglement as before.)\n",
    "\n",
    "One thing we can do with the spin coherent states is use them to define a \"wavefunction\" on $S^{2}$, the sphere, corresponding to our spin state. Given a spin state $\\mid \\psi \\rangle$, \n",
    "\n",
    "$\\psi(x, y, z) = \\langle (x, y, z) \\mid \\psi \\rangle$, where $\\langle (x, y, z) \\mid$ is the spin coherent state with $2j$ stars at $(x, y, z)$.\n",
    "\n",
    "This wave function will be 0 at the points directly opposite to the Majorana stars. This makes sense because $\\psi(x, y, z)$ is the probability amplitude for *all the stars to be at $(x, y, z)$*, but we know that there's a star in the opposite direction, so the amplitude has to be 0 at $(x, y, z)$. So its zeros are precisely opposite to the zeros of the Majorana polynomial. (There's a normalization factor I'm ignoring here.)\n",
    "\n",
    "This gives us an operational meaning for the individual stars. They represent the directions along which there is 0% probability that the spin will be entirely in the opposite direction. And the state on the whole sphere can be completely characterized by these points.\n",
    "\n",
    "And moreover, we've been able to reframe the superposition of constellations in terms of something we can understand: the superposition of waves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qutip as qt\n",
    "import vpython as vp\n",
    "from magic import *\n",
    "scene = vp.canvas(background=vp.color.white)\n",
    "\n",
    "def coherent_states(j, N=25):\n",
    "    theta = np.linspace(0, math.pi, N)\n",
    "    phi = np.linspace(0, 2*math.pi, N)\n",
    "    THETA, PHI = np.meshgrid(theta, phi)\n",
    "    return ([[qt.spin_coherent(j, THETA[i][k], PHI[i][k])\\\n",
    "                    for k in range(N)] for i in range(N)], THETA, PHI)\n",
    "\n",
    "def husimi(state, CS):\n",
    "    cs, THETA, PHI = CS\n",
    "    N = len(THETA)\n",
    "    Q = np.zeros_like(THETA, dtype=complex)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            amplitude = cs[i][j].overlap(state)\n",
    "            Q[i][j] = amplitude#*np.conjugate(amplitude)\n",
    "    pts = []\n",
    "    for i, j, k in zip(Q, THETA, PHI):\n",
    "        for q, t, p in zip(i, j, k):\n",
    "            pts.append([q, sph_xyz([1, t, p])])\n",
    "    return pts\n",
    "\n",
    "def tangent_rotations(CS):\n",
    "    cs, THETA, PHI = CS\n",
    "    rots = []\n",
    "    for j, k in zip(THETA, PHI):\n",
    "        for t, p in zip(j, k):\n",
    "            normal = sph_xyz([1, t, p])\n",
    "            tan = sph_xyz([1, t+np.pi/2, p])\n",
    "            vv = np.cross(tan, normal)\n",
    "            vv = vv/np.linalg.norm(vv)\n",
    "            trans = np.array([tan, vv, normal])\n",
    "            itrans = np.linalg.inv(trans)\n",
    "            rots.append(itrans)\n",
    "    return rots\n",
    "\n",
    "dt = 0.01\n",
    "j = 3/2\n",
    "n = int(2*j+1)\n",
    "\n",
    "CS = coherent_states(j, N=20)\n",
    "rots = tangent_rotations(CS)\n",
    "\n",
    "state = qt.rand_ket(n)\n",
    "H = qt.rand_herm(n)\n",
    "U = (-1j*H*dt).expm()\n",
    "\n",
    "vsphere = vp.sphere(color=vp.color.blue,\\\n",
    "                    opacity=0.4)\n",
    "vstars = [vp.sphere(radius=0.2, emissive=True,\\\n",
    "                    pos=vp.vector(*xyz)) for xyz in spin_XYZ(state)]\n",
    "\n",
    "pts = husimi(state, CS)\n",
    "#vpts = [vp.sphere(pos=vp.vector(*pt[1]), radius=0.5*pt[0]) for pt in pts]\n",
    "vpts = []\n",
    "for i, pt in enumerate(pts):\n",
    "    amp, normal = pt\n",
    "    amp_vec = np.array([amp.real, amp.imag, 0])\n",
    "    amp_vec = np.dot(rots[i], amp_vec)\n",
    "    vpts.append(vp.arrow(pos=vp.vector(*normal), axis=0.5*vp.vector(*amp_vec)))\n",
    "\n",
    "while True:\n",
    "    state = U*state\n",
    "    for i, xyz in enumerate(spin_XYZ(state)):\n",
    "        vstars[i].pos = vp.vector(*xyz)\n",
    "    pts = husimi(state, CS)\n",
    "    #for i, pt in enumerate(pts):\n",
    "    #    vpts[i].radius = 0.5*pt[0]\n",
    "    for i, pt in enumerate(pts):\n",
    "        amp, normal = pt\n",
    "        amp_vec = np.array([amp.real, amp.imag, 0])\n",
    "        amp_vec = np.dot(rots[i], amp_vec)\n",
    "        vpts[i].axis = 0.5*vp.vector(*amp_vec)\n",
    "    vp.rate(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One is reminded of the (in)famous Hairy Ball theorem, which says that if you have a hairy ball and try to comb its hair flat, no matter how hard you try, there will always be one hair like Alfalfa's that'll always be sticking up. That single hair? It's the point at infinity.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Okay, now we're going to shift gears a little bit. It turns out that there is another related and very useful representation of a spin-$j$ particle.\n",
    "\n",
    "Specifically, there's a 1-to-1 map between spin-$j$ states and the symmeterized tensor product of $2j$ spin-$\\frac{1}{2}$ states. And you'll never guess: the spin-$\\frac{1}{2}$ states we symmeterize are the spinors corresponding to the roots from before.\n",
    "\n",
    "Consider we have two spin-$\\frac{1}{2}$ states $\\begin{pmatrix} a \\\\ b \\end{pmatrix}$ and $\\begin{pmatrix} c \\\\ d \\end{pmatrix}$. Their homogeneous polynomials are: $f(w, z) = az - bw$ and $g(w, z) = cz - dw$. Let's multiply them together: $h(w, z) = (az - bw)(cz - dw) = acz^{2} - adzw - bcwz + bdw^{2} = acz^{2} - (ad + bc)zw + bdw^{2}$. Converting things into a $\\mid j, m \\rangle$ state, we get: $\\begin{pmatrix} \\frac{ac}{ (-1)^{0}\\sqrt{\\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}}} \\\\ \\frac{-(ad + bc)}{(-1)^{1}\\sqrt{\\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}}} \\\\ \\frac{bd}{(-1)^{2}\\sqrt{\\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}}} \\end{pmatrix}$ or $\\begin{pmatrix} ac \\\\ \\frac{1}{\\sqrt{2}}(ad + bc) \\\\ bd \\end{pmatrix}$. This is a spin-$1$ state.\n",
    "\n",
    "On the other hand, let's consider the permutation symmetric tensor product of our two states:\n",
    "\n",
    "$ \\frac{1}{2} \\Big{(} \\begin{pmatrix} a \\\\ b \\end{pmatrix} \\otimes \\begin{pmatrix} c \\\\ d \\end{pmatrix} + \\begin{pmatrix} c \\\\ d \\end{pmatrix} \\otimes \\begin{pmatrix} a \\\\ b \\end{pmatrix} \\Big{)} = \\frac{1}{2} \\Big{(} \\begin{pmatrix} ac \\\\ ad \\\\ bc \\\\ bd \\end{pmatrix} + \\begin{pmatrix} ca \\\\ cb \\\\ da \\\\ db \\end{pmatrix} \\Big{)} = \\begin{pmatrix} ac \\\\ \\frac{1}{2}(ad + bc) \\\\ \\frac{1}{2}(ad + bc) \\\\ bd \\end{pmatrix}$.\n",
    "\n",
    "Just looking at the components we can see that the spin-$1$ state and the permutation symmetric product of the two spin-$\\frac{1}{2}$ states are really encoding the same information.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider that the following states form a basis for the permutation symmetric states of two spin-$\\frac{1}{2}$'s:\n",
    "\n",
    "$\\begin{matrix} \n",
    "\\mid \\uparrow \\uparrow \\rangle \\\\ \n",
    "\\mid \\uparrow \\downarrow \\rangle \\ + \\mid \\downarrow \\uparrow \\rangle \\\\ \n",
    "\\mid \\downarrow \\downarrow \\rangle\n",
    "\\end{matrix}$\n",
    "\n",
    "The permutation symmetric subspace is 3 dimensional, just like a spin-$1$ state! (We could normalize the middle term with a $\\frac{1}{\\sqrt{2}}$, etc.)\n",
    "\n",
    "For three spin-$\\frac{1}{2}$'s:\n",
    "\n",
    "$\\begin{matrix} \n",
    "\\mid \\uparrow \\uparrow \\uparrow \\rangle \\\\ \n",
    "\\mid \\uparrow \\uparrow \\downarrow \\rangle \\ + \\mid \\uparrow \\downarrow \\uparrow \\rangle \\ + \\mid \\downarrow \\uparrow \\uparrow \\rangle \\\\ \n",
    "\\mid \\downarrow \\downarrow \\uparrow \\rangle \\ + \\mid \\downarrow \\uparrow \\downarrow \\rangle \\ + \\mid \\uparrow \\downarrow \\downarrow \\rangle \\\\ \n",
    "\\mid \\downarrow \\downarrow \\downarrow \\rangle\n",
    "\\end{matrix}$\n",
    "\n",
    "It's four dimensional, just like a spin-$\\frac{3}{2}$ state!\n",
    "\n",
    "For four:\n",
    "\n",
    "$\\begin{matrix} \n",
    "\\mid \\uparrow \\uparrow \\uparrow \\uparrow \\rangle \\\\ \n",
    "\\mid \\uparrow \\uparrow \\uparrow \\downarrow \\rangle \\ + \\mid \\uparrow \\uparrow \\downarrow \\uparrow \\rangle \\ + \\mid \\uparrow \\downarrow \\uparrow \\uparrow \\rangle \\ + \\mid \\downarrow \\uparrow \\uparrow \\uparrow \\rangle \\\\ \n",
    "\\mid \\uparrow \\uparrow \\downarrow \\downarrow \\rangle \\ + \\mid \\uparrow \\downarrow \\downarrow \\uparrow \\rangle \\ + \\mid \\uparrow \\downarrow \\uparrow \\downarrow \\rangle \\ + \\mid \\downarrow \\uparrow \\downarrow \\uparrow \\rangle \\ + \\mid \\downarrow \\uparrow \\uparrow \\downarrow \\rangle \\ + \\mid \\downarrow \\downarrow \\uparrow \\uparrow \\rangle \\\\\n",
    "\\mid \\downarrow \\downarrow \\downarrow \\uparrow \\rangle \\ + \\mid \\downarrow \\downarrow \\uparrow \\downarrow \\rangle \\ + \\mid \\downarrow \\uparrow \\downarrow \\downarrow \\rangle \\ + \\mid \\uparrow \\downarrow \\downarrow \\downarrow \\rangle \\\\ \n",
    "\\mid \\downarrow \\downarrow \\downarrow \\downarrow \\rangle\n",
    "\\end{matrix}$\n",
    "\n",
    "It's five dimensional, just like a spin-$2$ state!\n",
    "\n",
    "We can see that the symmeterized basis states are just sums over the states with: all $\\uparrow$, all but one $\\uparrow$, all but two $\\uparrow$, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qutip as qt\n",
    "import numpy as np\n",
    "from magic import spin_XYZ\n",
    "from itertools import permutations, product\n",
    "\n",
    "def spin_sym_trans(j):\n",
    "    n = int(2*j)\n",
    "    if n == 0:\n",
    "        return qt.Qobj([1])\n",
    "    N = {}\n",
    "    for p in product([0,1], repeat=n):\n",
    "        if p.count(1) in N:\n",
    "            N[p.count(1)] += qt.tensor(*[qt.basis(2, i) for i in p])\n",
    "        else:\n",
    "            N[p.count(1)] = qt.tensor(*[qt.basis(2, i) for i in p])\n",
    "    Q = qt.Qobj(np.array([N[i].unit().full().T[0].tolist() for i in range(n+1)]))\n",
    "    Q.dims[1] = [2]*n\n",
    "    return Q.dag()\n",
    "\n",
    "def spin_sym(spin):\n",
    "    spinors = [qt.Qobj(c_spinor(r)) for r in spin_roots(spin)]\n",
    "    return sum([qt.tensor(*[spinors[i] for i in p]) for p in permutations(range(len(spinors)))]).unit()\n",
    "\n",
    "def get_phase(v):\n",
    "    c = None\n",
    "    if isinstance(v, qt.Qobj):\n",
    "        v = v.full().T[0]\n",
    "    i = (v!=0).argmax(axis=0)\n",
    "    c = v[i]\n",
    "    return np.exp(1j*np.angle(c))\n",
    "\n",
    "def normalize_phase(v):\n",
    "    return v/get_phase(v)\n",
    "\n",
    "j = 3/2\n",
    "n = int(2*j + 1)\n",
    "spin = qt.rand_ket(n)\n",
    "S = spin_sym_trans(j)\n",
    "\n",
    "sym = S*spin\n",
    "spin2 = S.dag()*sym\n",
    "print(spin)\n",
    "print(sym)\n",
    "print(spin == spin2)\n",
    "\n",
    "sym2 = spin_sym(spin)\n",
    "print(np.isclose(normalize_phase(sym).full().T[0], normalize_phase(sym2).full().T[0]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we calculate our symmeterized state in two ways. First, we calculate the symmeterized basis states and make a change-of-basis matrix that transforms our $\\mid j, m \\rangle$ state into a symmeterized state of $2j$ spin-$\\frac{1}{2}$'s. The symmeterized basis states (in the order given above) are paired with the $\\mid j, m \\rangle$ states in their usual order, from largest $m$ to smallest $m$. We also show we can undo the transformation without any harm.\n",
    "\n",
    "Second, we find the roots of the associated polynomial of the $\\mid j, m\\rangle$ state, upgrade the roots to spinors, and then tensor them in all possible orders, and add up all the permutations, normalizing the state in the end. We find that we get exactly the same symmeterized state! Up to complex phase, however. So we normalize the phases (basically, impose that the first (non-0) component is real), and behold: it's precisely the same symmeterized state.\n",
    "\n",
    "One nice thing that immediate follows from this is that we can actually explicitly calculate the X, Y, Z matrices for any spin-$j$. If we wanted the X matrix for spin-$\\frac{3}{2}$, for example, we'd just take:\n",
    "\n",
    "$X_{sym} = (X_{\\frac{1}{2}} \\otimes I \\otimes I) + (I \\otimes X_{\\frac{1}{2}} \\otimes I) + (I \\otimes I \\otimes X_{\\frac{1}{2}})$\n",
    "\n",
    "This applies the Pauli X matrix to each of the symmeterized spin-$\\frac{1}{2}$ guys each separately. Then we downgrade this to act on our $\\mid j, m \\rangle$ vector with $X_{\\frac{3}{2}} = S^{\\dagger} X_{sym} S$, where $S$ is our change-of-basis matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qutip as qt\n",
    "import numpy as np\n",
    "from magic import spin_XYZ\n",
    "from itertools import permutations, product\n",
    "\n",
    "def spin_sym_trans(j):\n",
    "    n = int(2*j)\n",
    "    if n == 0:\n",
    "        return qt.Qobj([1])\n",
    "    N = {}\n",
    "    for p in product([0,1], repeat=n):\n",
    "        if p.count(1) in N:\n",
    "            N[p.count(1)] += qt.tensor(*[qt.basis(2, i) for i in p])\n",
    "        else:\n",
    "            N[p.count(1)] = qt.tensor(*[qt.basis(2, i) for i in p])\n",
    "    Q = qt.Qobj(np.array([N[i].unit().full().T[0].tolist() for i in range(n+1)]))\n",
    "    Q.dims[1] = [2]*n\n",
    "    return Q.dag()\n",
    "\n",
    "j = 3/2\n",
    "n = int(2*j + 1)\n",
    "spin = qt.rand_ket(n)\n",
    "S = spin_sym_trans(j)\n",
    "\n",
    "X = S.dag()*sum([qt.tensor(*[qt.jmat(0.5, 'x') if i == j else qt.identity(2)\\\n",
    "            for j in range(n-1)]) for i in range(n-1)])*S\n",
    "Y = S.dag()*sum([qt.tensor(*[qt.jmat(0.5, 'y') if i == j else qt.identity(2)\\\n",
    "            for j in range(n-1)]) for i in range(n-1)])*S\n",
    "Z = S.dag()*sum([qt.tensor(*[qt.jmat(0.5, 'z') if i == j else qt.identity(2)\\\n",
    "            for j in range(n-1)]) for i in range(n-1)])*S\n",
    "\n",
    "print(X == qt.jmat(j, 'x'))\n",
    "print(Y == qt.jmat(j, 'y'))\n",
    "print(Z == qt.jmat(j, 'z'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So anyway this is interesting. We can represent our spin-$j$ state as: a set of roots/$(x, y, z)$ points, a single variable polynomial, a homogeneous two variable polynomial, a $\\mid j, m \\rangle$ state, and also a state of $2j$ symmeterized spin-$\\frac{1}{2}$'s. In the latter case, we can swap any of the symmeterized qubits and this doesn't change the constellation. Indeed, the constellation is \"holistically\" encoded in the entanglement between the parts and not in the parts (qubits) individually. What does this mean operationally? \n",
    "\n",
    "Well, suppose we just rotate a single one of the symmeterized qubits around the X axis a bit. This won't lead to a rigid rotation of the whole sphere. In fact, we're no longer in a permutation symmetry state! But a local rotation can't change the entanglement between the parts in any way. Indeed, if we then rotate the rest of the qubits in exactly the same, we can recover our original constellation (just rotated around the X-axis)! In other words, the constellation isn't ultimately affected by local rotations of the qubits: we can rotate all the qubits separately locally, but the constellation is still in there somewhere--there will always be a way to undo all those changes and recover the constellation by acting locally separately on the qubits. In this sense, the constellation is encoded in the entanglement of the whole and not in the parts.\n",
    "\n",
    "Indeed, we could separate the $2j$ spin-$\\frac{1}{2}$ particles and distribute them to $2j$ parties. The constellation is still encoded in them, even though the individual parts might be scattered around the universe!\n",
    "\n",
    "<hr >\n",
    "\n",
    "There's an idea that goes by the name SLOCC: Stochastic Local Operations and Classical Communication. The idea is: we want to describe what's invariant about a multipartite quantum state, in other words, characterize its entanglement structure, supposing we can: act separately with unitaries on the parts, classically communicate to each each other (like if we each had one of the parts), and also: entangle our part with some auxilliary system (which will change the entanglement structure), but then measure the auxilliary system (which will restore the entanglement structure). (In this context, if we do the same auxilliary operation to all the qubits, we can *boost* the constellation: we can implement not just SU(2), but also SL(2,C)). By coordinating our local operations, we can always recover the original constellation by local ops: we can always turn local rotations/boosts into global rotations/boosts by making sure each qubit is rotated in the same way.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another great thing about the symmeterized qubit representation of spin is that it makes calculating spin couplings aka \"the addition of angular momentum\" very elegant! Normally, we need to calculate a basis transformation in terms of the so-called Clebsch-Gordan coefficients, or find the eigenvalues/eigenvectors of the total spin operator, but we can get the same answer in a very cool way with our symmeterized states.\n",
    "\n",
    "So what are we talking about it? It's a kind of generalization of the Fourier transform to SU(2). Suppose we have two spin-$\\frac{1}{2}$ particles tensored together. We normally describe this in terms of the standard tensor basis: $\\{\\mid \\uparrow \\uparrow \\rangle, \\mid \\uparrow \\downarrow \\rangle, \\mid \\downarrow \\uparrow \\rangle, \\mid \\downarrow \\downarrow \\rangle \\}$. But we could also expand it in another basis, for example, in terms of eigenstates of the total spin operator: $J^{2} = \\textbf{XX} + \\textbf{YY} + \\textbf{ZZ}$, where $\\textbf{X}$ is the sum of the X operators on each of the spins, $\\textbf{Y}$ is the sum of the Y operators on each of the spins, etc, each tensored with identities appropriately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qutip as qt\n",
    "import numpy as np\n",
    "\n",
    "def symmeterize(qubits):\n",
    "    return sum(qt.tensor(*perm)\\\n",
    "        for perm in permutations(qubits, len(qubits))).unit()\n",
    "\n",
    "j1, j2 = 1/2, 1/2\n",
    "n1, n2 = int(2*j1+1), int(2*j2+1)\n",
    "state = qt.rand_ket(n1*n2)\n",
    "state.dims = [[n1,n2], [1,1]]\n",
    "\n",
    "X = qt.tensor(qt.jmat(j1, 'x'), qt.identity(n2)) + qt.tensor(qt.identity(n1), qt.jmat(j2, 'x'))\n",
    "Y = qt.tensor(qt.jmat(j1, 'y'), qt.identity(n2)) + qt.tensor(qt.identity(n1), qt.jmat(j2, 'y'))\n",
    "Z = qt.tensor(qt.jmat(j1, 'z'), qt.identity(n2)) + qt.tensor(qt.identity(n1), qt.jmat(j2, 'z'))\n",
    "\n",
    "J = X*X + Y*Y + Z*Z\n",
    "JL, JV = J.eigenstates()\n",
    "M = qt.Qobj(np.array([v.full().T[0] for v in JV]))\n",
    "M.dims = [[n1,n2], [n1,n2]]\n",
    "state2 = M*state\n",
    "print(M)\n",
    "print(state2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the rows of $M$, which are the eigenvectors of $J^{2}$, we find that the following provide an alternative basis for the states of two qubits:\n",
    "\n",
    "$\\begin{matrix}\n",
    "\\mid \\uparrow \\downarrow \\rangle \\ - \\mid \\downarrow \\uparrow \\rangle \\\\\n",
    "\\mid \\uparrow \\uparrow \\rangle \\\\\n",
    "\\mid \\uparrow \\downarrow \\rangle \\ + \\mid \\downarrow \\uparrow \\rangle \\\\\n",
    "\\mid \\downarrow \\downarrow \\rangle\n",
    "\\end{matrix}\n",
    "$\n",
    "\n",
    "Well, we recognize the latter three basis states as just the 3 permutation symmetric states from before! So the last three components in this basis correspond to a spin-$1$ state. The first basis state, in contrast, is the antisymmetric state: there's only one of them, and this corresponds to a spin-$0$ state, a singlet. (This 1+3 decomposition is deeply related to the 1+3 structure of a Minkowski vector.) \n",
    "\n",
    "So we can decompose the tensor product of two spin-$\\frac{1}{2}$ states into a \"direct sum\" or concatenation of a spin-$0$ state and a spin-$1$ state.\n",
    "\n",
    "$ H_{\\frac{1}{2}} \\otimes H_{\\frac{1}{2}} \\rightarrow H_{0} \\oplus H_{1}$\n",
    "\n",
    "I like to think of this like: we can turn a spin-$\\frac{1}{2}$ AND a spin-$\\frac{1}{2}$ into a spin-$0$ OR a spin-$1$. It's like finding the \"spectrum\": but instead of a direct sum of \"frequencies\", we get a direct sum of spin sectors. If the \"product/tensor\" basis makes manifest the fact that there are two \"separate\" particles (which might be entangled), the \"Clebsch-Gordan basis\" makes manifest their togetherness. Moreover, it's worth pointing out that a concatenation of Hilbert spaces is also a Hilbert space. The spin-${0}$ sector and the spin-${1}$ sector are each weighted by an amplitude, like: $\\begin{pmatrix} a_{j=0} \\\\ b_{j=1} \\end{pmatrix}$, with $aa^{*} + bb^{*} = 1$. So we can interpret $a$ and $b$ as the probability amplitudes that if two spin-$\\frac{1}{2}$'s come in, depending on their state, they'll combine into either a spin-$0$ or a spin-$1$.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have for example:\n",
    "\n",
    "$ H_{\\frac{1}{2}} \\otimes H_{1} \\rightarrow H_{\\frac{1}{2}} \\oplus H_{\\frac{3}{2}}$\n",
    "\n",
    "$ H_{\\frac{1}{2}} \\otimes H_{\\frac{3}{2}} \\rightarrow H_{1} \\oplus H_{2}$\n",
    "\n",
    "In other words, if we combine a spin-$\\frac{1}{2}$ and a spin-$j$, we get either a spin-($j+\\frac{1}{2}$) or spin-($j-\\frac{1}{2}$).\n",
    "\n",
    "$ H_{1} \\otimes H_{1} \\rightarrow H_{0} \\oplus H_{1} \\oplus H_{2}$\n",
    "\n",
    "Indeed, $3 \\times 3 = 1 + 3 + 5 = 9$. So the dimensionality checks out.\n",
    "\n",
    "$ H_{1} \\otimes H_{2} \\rightarrow H_{1} \\oplus H_{2} \\oplus H_{3}$\n",
    "\n",
    "As: $3 \\times 5 = 3 + 5 + 7 = 15$.\n",
    "\n",
    "$ H_{1} \\otimes H_{\\frac{3}{2}} \\rightarrow H_{\\frac{1}{2}} \\oplus H_{\\frac{3}{2}} \\oplus H_{\\frac{5}{2}}$\n",
    "\n",
    "As: $3 \\times 4 = 2 + 4 + 6 = 12$.\n",
    "\n",
    "$ H_{\\frac{3}{2}} \\otimes H_{\\frac{3}{2}} \\rightarrow H_{0} \\oplus H_{1} \\oplus H_{2} \\oplus H_{3}$\n",
    "\n",
    "As: $4 \\times 4 = 1 + 3 + 5 + 7 = 16$.\n",
    "\n",
    "And if we have more than two spins, we can iterate this construction (you may have to take into account the different orders one could combine the spins in). \n",
    "\n",
    "E.g., $H_{\\frac{1}{2}} \\otimes H_{\\frac{1}{2}} \\otimes H_{\\frac{1}{2}} \\otimes H_{\\frac{1}{2}} = (H_{0} \\oplus H_{1}) \\otimes (H_{0} \\oplus H_{1}) = H_{0} \\oplus H_{1} \\oplus H_{1} \\oplus H_{0} \\oplus H_{1} \\oplus H_{2} = (H_{0} \\oplus H_{0}) \\oplus (H_{1} \\oplus H_{1} \\oplus H_{1}) \\oplus (H_{2})$.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so we can calculate this decomposition by just diagonalizing the total spin operator (and making sure the basis states are in the right order!). But here's another way:\n",
    "\n",
    "First we define $\\epsilon = \\begin{pmatrix} 0 \\\\ 1 \\\\ -1 \\\\ 0 \\end{pmatrix}$: it's just the (unnormalized) antisymmetric state of two spin-$\\frac{1}{2}$'s. Now suppose we have two spins with $j_{1}$ and $j_{2}$, each represented as the symmetrized tensor product of $2j$ spinors. We tensor them together. If we then symmeterize over *all* the spinors, we obtain a spin-($j_{1} + j_{2}$) state. If we started with two separable spins, the resulting constellation is just given by: the constellation of the first spin overlaid with the constellation of the second spin. If we had two spin-$\\frac{1}{2}$'s, this would be the spin-$1$ state. To get the rest of the states, before we symmeterize, we contract $k$ spinors of the first group with $k$ spinors of the second group using the $\\epsilon$. In other words, we contract a spinor from the first group with the first spinor in $\\epsilon$ and a spinor from the second group with the second spinor in $\\epsilon$. Once we've contracted k spinors, we symmeterize the $2(j_{1} + j_{2} - k)$ spinors which are left. By going over all the possible k's, we obtain the Clebsch-Gordan decomposition.\n",
    "\n",
    "Now the normalization of the states is a little tricky so let's ignore that! It's the principle that matters: to get each lower state, we remove a star's worth of angular momentum from each of the two groups: and the use of the $\\epsilon$ imposes angular momentum conservation. (Note because of the permutation symmetry, it doesn't matter which spinors we choose to contract within a group!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qutip as qt\n",
    "from itertools import permutations, product\n",
    "from magic import *\n",
    "\n",
    "######################################################\n",
    "\n",
    "def spin_sym_trans(j):\n",
    "    n = int(2*j)\n",
    "    if n == 0:\n",
    "        return qt.Qobj(np.array([1]))\n",
    "    N = {}\n",
    "    for p in product([0,1], repeat=n):\n",
    "        if p.count(1) in N:\n",
    "            N[p.count(1)] += qt.tensor(*[qt.basis(2, i) for i in p])\n",
    "        else:\n",
    "            N[p.count(1)] = qt.tensor(*[qt.basis(2, i) for i in p])\n",
    "    Q = qt.Qobj(np.array([N[i].unit().full().T[0].tolist() for i in range(n+1)]))\n",
    "    Q.dims[1] = [2]*n\n",
    "    return Q.dag()\n",
    "\n",
    "######################################################\n",
    "\n",
    "def symmeterize_indices(tensor, dims):\n",
    "    tensor = tensor.copy()\n",
    "    old_dims = tensor.dims\n",
    "    tensor.dims = [dims, [1]*len(dims)]\n",
    "    n = tensor.norm()\n",
    "    pieces = [tensor.permute(p) for p in permutations(list(range(len(tensor.dims[0]))))]\n",
    "    for piece in pieces:\n",
    "        piece.dims = [[piece.shape[0]], [1]]\n",
    "    v = sum(pieces)/len(pieces)\n",
    "    v.dims = old_dims\n",
    "    return v\n",
    "\n",
    "######################################################\n",
    "\n",
    "def clebsch_split(state, sectors):\n",
    "    v = state.full().T[0]\n",
    "    dims = [int(2*sector + 1) for sector in sectors]\n",
    "    running = 0\n",
    "    clebsch_states = []\n",
    "    for d in dims:\n",
    "        clebsch_states.append(qt.Qobj(v[running:running+d]))\n",
    "        running += d\n",
    "    return clebsch_states\n",
    "\n",
    "def possible_j3s(j1, j2):\n",
    "    J3 = [j1-m2 for m2 in np.arange(-j2, j2+1)]\\\n",
    "            if j1 > j2 else\\\n",
    "                [j2-m1 for m1 in np.arange(-j1, j1+1)]\n",
    "    return J3[::-1]\n",
    "\n",
    "def tensor_clebsch(j1, j2):\n",
    "    J3 = possible_j3s(j1, j2)\n",
    "    states = []\n",
    "    labels = []\n",
    "    for j3 in J3:\n",
    "        substates = []\n",
    "        sublabels = []\n",
    "        for m3 in np.arange(-j3, j3+1):\n",
    "            terms = []\n",
    "            for m1 in np.arange(-j1, j1+1):\n",
    "                for m2 in np.arange(-j2, j2+1):\n",
    "                    terms.append(\\\n",
    "                        qt.clebsch(j1, j2, j3, m1, m2, m3)*\\\n",
    "                        qt.tensor(qt.spin_state(j1, m1),\\\n",
    "                                    qt.spin_state(j2, m2)))\n",
    "            substates.append(sum(terms))\n",
    "            sublabels.append((j3, m3))\n",
    "        states.extend(substates[::-1])\n",
    "        labels.append(sublabels[::-1])\n",
    "    return qt.Qobj(np.array([state.full().T[0] for state in states])), labels\n",
    "\n",
    "######################################################\n",
    "\n",
    "j1, j2 = 1/2, 1/2# make sure the smaller spin is first\n",
    "n1, n2 = int(2*j1+1), int(2*j2+1)\n",
    "state = qt.rand_ket(n1*n2)\n",
    "state.dims = [[n1,n2], [1,1]]\n",
    "\n",
    "######################################################\n",
    "\n",
    "CG, labels = tensor_clebsch(j1, j2)\n",
    "CG.dims = [state.dims[0], state.dims[0]]\n",
    "cg_state = CG*state\n",
    "cgr = clebsch_split(cg_state, possible_j3s(j1, j2))\n",
    "for i, r in enumerate(cgr):\n",
    "    if r.shape[0] != 1:\n",
    "        cgr[i] = normalize_phase(r.unit())\n",
    "    else:\n",
    "        cgr[i] = cgr[i].unit()\n",
    "\n",
    "######################################################\n",
    "\n",
    "def repair(q):\n",
    "    q.dims[1] = [1]*len(q.dims[0])\n",
    "    return q\n",
    "\n",
    "S1, S2 = spin_sym_trans(j1), spin_sym_trans(j2)\n",
    "S = qt.tensor(S1, S2)\n",
    "together = S*state\n",
    "\n",
    "a_indices = [2]*(n1-1)\n",
    "b_indices = [2]*(n2-1)\n",
    "results = [repair(symmeterize_indices(together, together.dims[0]))]\n",
    "contracted = [together.copy()]\n",
    "for i in range(int(2*j1)):\n",
    "    if contracted[-1].dims[0] == [2,2]:\n",
    "        results.append(np.sqrt(2)*qt.singlet_state().dag()*contracted[-1])\n",
    "    else:\n",
    "        intermediate = qt.tensor(np.sqrt(2)*qt.singlet_state(), contracted[-1])\n",
    "        intermediate = repair(qt.tensor_contract(intermediate, (0, 2)))\n",
    "        a_indices.pop()\n",
    "        if intermediate.dims[0] == [2,2]:\n",
    "            results.append(np.sqrt(2)*qt.singlet_state().dag()*intermediate)\n",
    "        else:\n",
    "            intermediate = repair(qt.tensor_contract(intermediate, (0, len(intermediate.dims[0])-1)))\n",
    "            b_indices.pop()\n",
    "            contracted.append(intermediate.copy())\n",
    "            if intermediate.dims[0] != [2]:\n",
    "                results.append(repair(symmeterize_indices(intermediate, intermediate.dims[0])))\n",
    "            else:\n",
    "                results.append(intermediate.copy())\n",
    "\n",
    "cgr2 = []\n",
    "for result in results:\n",
    "    if result.shape[0] == 1:\n",
    "        cgr2.append(result.unit())\n",
    "    else:\n",
    "        SR = spin_sym_trans(len(result.dims[0])/2)\n",
    "        temp = repair(normalize_phase(SR.dag()*result))\n",
    "        if temp.norm() != 0:\n",
    "            temp = temp.unit()\n",
    "        cgr2.append(temp)\n",
    "cgr2 = cgr2[::-1]\n",
    "\n",
    "print(cgr)\n",
    "print(cgr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see whether the above algorithm worked, we use qutip's built-in Clebsch-Gordan calculator. We construct the basis transformation given $j_{1}$ and $j_{2}$ by iterating over the possible $j$'s that can result. For each possible output $j$, we iterate over its possible $m$ values. For each one, we iterate over the possible $m_{1}$ and $m_{2}$ values for $j_{1}$ and $j_{2}$: for each $(j_{1}, j_{2}, j, m_{1}, m_{2}, m)$, we get the Clebsch-Gordan coefficient, which weights the state $\\mid j_{1}, m_{1} \\rangle \\mid j_{2}, m_{2}\\rangle$. We then sum all those states (for the $m$ value of $j$). We repeat the procedure for each $m$ value of $j$. We stick all those states into a matrix, and that gives us our basis transformation.\n",
    "\n",
    "Anyway, let's see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qutip as qt\n",
    "import numpy as np\n",
    "from magic import *\n",
    "import vpython as vp\n",
    "\n",
    "######################################################\n",
    "\n",
    "def clebsch_split(state, sectors):\n",
    "    v = state.full().T[0]\n",
    "    dims = [int(2*sector + 1) for sector in sectors]\n",
    "    running = 0\n",
    "    clebsch_states = []\n",
    "    for d in dims:\n",
    "        clebsch_states.append(qt.Qobj(v[running:running+d]))\n",
    "        running += d\n",
    "    return clebsch_states\n",
    "\n",
    "def possible_j3s(j1, j2):\n",
    "    J3 = [j1-m2 for m2 in np.arange(-j2, j2+1)]\\\n",
    "            if j1 > j2 else\\\n",
    "                [j2-m1 for m1 in np.arange(-j1, j1+1)]\n",
    "    return J3[::-1]\n",
    "\n",
    "def tensor_clebsch(j1, j2):\n",
    "    J3 = possible_j3s(j1, j2)\n",
    "    states = []\n",
    "    labels = []\n",
    "    for j3 in J3:\n",
    "        substates = []\n",
    "        sublabels = []\n",
    "        for m3 in np.arange(-j3, j3+1):\n",
    "            terms = []\n",
    "            for m1 in np.arange(-j1, j1+1):\n",
    "                for m2 in np.arange(-j2, j2+1):\n",
    "                    terms.append(\\\n",
    "                        qt.clebsch(j1, j2, j3, m1, m2, m3)*\\\n",
    "                        qt.tensor(qt.spin_state(j1, m1),\\\n",
    "                                    qt.spin_state(j2, m2)))\n",
    "            substates.append(sum(terms))\n",
    "            sublabels.append((j3, m3))\n",
    "        states.extend(substates[::-1])\n",
    "        labels.append(sublabels[::-1])\n",
    "    return qt.Qobj(np.array([state.full().T[0] for state in states])), labels\n",
    "\n",
    "######################################################\n",
    "\n",
    "j1, j2 = 1,2# make sure the smaller spin is first\n",
    "n1, n2 = int(2*j1+1), int(2*j2+1)\n",
    "state = qt.tensor(qt.rand_ket(n1), qt.rand_ket(n2))#qt.rand_ket(n1*n2)\n",
    "state.dims = [[n1,n2], [1,1]]\n",
    "\n",
    "######################################################\n",
    "\n",
    "CG, labels = tensor_clebsch(j1, j2)\n",
    "CG.dims = [state.dims[0], state.dims[0]]\n",
    "cg_state = CG*state\n",
    "poss_js = possible_j3s(j1, j2)\n",
    "cgr = clebsch_split(cg_state, poss_js)\n",
    "\n",
    "######################################################\n",
    "\n",
    "Astate = state.ptrace(0)\n",
    "AL, AV = Astate.eigenstates()\n",
    "Bstate = state.ptrace(1)\n",
    "BL, BV = Bstate.eigenstates()\n",
    "vsphereA = vp.sphere(pos=vp.vector(-2, 5, 0), radius=j1, opacity=0.5, color=vp.color.blue)\n",
    "vstarsA = [[vp.sphere(pos=vsphereA.pos + vsphereA.radius*vp.vector(*xyz),\\\n",
    "                      radius=0.2*vsphereA.radius,\\\n",
    "                      opacity=AL[i])\\\n",
    "                 for xyz in spin_XYZ(v)] for i,v in enumerate(AV)]\n",
    "vsphereB = vp.sphere(pos=vp.vector(2, 5, 0), radius=j2, opacity=0.5, color=vp.color.blue)\n",
    "vstarsB = [[vp.sphere(pos=vsphereB.pos + vsphereB.radius*vp.vector(*xyz),\\\n",
    "                      radius=0.2*vsphereB.radius,\\\n",
    "                      opacity=BL[i])\\\n",
    "                 for xyz in spin_XYZ(v)] for i,v in enumerate(BV)]\n",
    "\n",
    "vcgspheres = []\n",
    "vcgstars = []\n",
    "colors = [vp.color.red, vp.color.orange, vp.color.yellow, vp.color.green, vp.color.blue, vp.color.magenta, vp.color.cyan]\n",
    "lengths = [c.shape[0] for c in cgr]\n",
    "L = sum(lengths)/2\n",
    "running = -L\n",
    "for i, c in enumerate(cgr):\n",
    "    if c.shape[0] == 1:\n",
    "        z = c.unit()\n",
    "        vsph = vp.arrow(color=colors[i], opacity=c.norm(), pos=vp.vector(running, -2, 0),\\\n",
    "                        axis=vp.vector(z[0][0][0].real, z[0][0][0].imag, 0))\n",
    "        vcgspheres.append(vsph)\n",
    "        vcgstars.append([])\n",
    "        running += 4\n",
    "    else:\n",
    "        vsph = vp.sphere(radius=(c.shape[0]-1)/2,\\\n",
    "                         pos=vp.vector(running, -2, 0),\\\n",
    "                         opacity=c.norm(),\\\n",
    "                         color=colors[i])\n",
    "        vsts = [vp.sphere(radius=0.2*vsph.radius, \\\n",
    "                          pos=vsph.pos + vsph.radius*vp.vector(*xyz))\\\n",
    "                            for xyz in spin_XYZ(c)]\n",
    "        vcgspheres.append(vsph)\n",
    "        vcgstars.append(vsts)\n",
    "        running += 1.5*c.shape[0]\n",
    "\n",
    "######################################################\n",
    "\n",
    "dt = 0.01\n",
    "H = qt.rand_herm(n1*n2)\n",
    "H.dims = [[n1, n2], [n1, n2]]\n",
    "U = (-1j*H*dt).expm()\n",
    "\n",
    "while True:\n",
    "    state = U*state\n",
    "\n",
    "    Astate = state.ptrace(0)\n",
    "    AL, AV = Astate.eigenstates()\n",
    "    Bstate = state.ptrace(1)\n",
    "    BL, BV = Bstate.eigenstates()\n",
    "\n",
    "    for i, v in enumerate(AV):\n",
    "        for j, xyz in enumerate(spin_XYZ(v)):\n",
    "            vstarsA[i][j].pos = vsphereA.pos + vsphereA.radius*vp.vector(*xyz)\n",
    "            vstarsA[i][j].opacity = AL[i]\n",
    "\n",
    "    for i, v in enumerate(BV):\n",
    "        for j, xyz in enumerate(spin_XYZ(v)):\n",
    "            vstarsB[i][j].pos = vsphereB.pos + vsphereB.radius*vp.vector(*xyz)\n",
    "            vstarsB[i][j].opacity = BL[i]\n",
    "\n",
    "    cg_state = CG*state\n",
    "    cgr = clebsch_split(cg_state, poss_js)\n",
    "    for i, c in enumerate(cgr):\n",
    "        if c.shape[0] == 1:\n",
    "            z = c.unit()\n",
    "            vcgspheres[i].opacity = c.norm()\n",
    "            vcgspheres[i].axis = vp.vector(z[0][0][0].real, z[0][0][0].imag, 0)\n",
    "        else:\n",
    "            vcgspheres[i].opacity = c.norm()\n",
    "            for j, xyz in enumerate(spin_XYZ(c)):\n",
    "                vcgstars[i][j].pos = vcgspheres[i].pos + vcgspheres[i].radius*vp.vector(*xyz)\n",
    "\n",
    "    vp.rate(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Now there's so much one could talk about here. One could talk about spin networks, originally developed by Penrose in the 60's. It gets at our issue about reference frames.\n",
    "\n",
    "You imagine a network of spin interactions, with edges labeled by $j$ values consistent with the addition of angular momenta. It turns out you can extract probabilities from a closed network without ever specifying the states per se, just the j values at the interactions--and these probabilities happen to be rational numbers. Penrose's motivation to look for an example of how space can emerge out of interaction. His reasoning was that we can only assign a state to a spin relative to some X, Y, Z axes, which presuppose that a shared 3D space exists. So instead of specifying the $\\mid j, m \\rangle$ state, he just wants to specify the $j$ values. He then wonders what happens when you consider the limit of large networks and high spin $j$'s, and he proves the Spin Geometry Theorem. The idea is this, suppose you have a large network, and in that context, a large $j$ spin. You could imagine it interacts with an additional single spin-$\\frac{1}{2}$ particle. Now either the interaction will result in a $j+\\frac{1}{2}$ or a $j-\\frac{1}{2}$ state, depending on the angle between the spins. But we know how to calculate probabilities using the spin network itself! (The rules are interesting and relate to our string diagram language from before, where the role of cup and cap is played by the $\\epsilon$. But we won't go into details here.) So imagine the network where the interaction results in a $j+\\frac{1}{2}$, and get the probability; and then the network where the interaction results in a $j-\\frac{1}{2}$, and get the probability. These two probabilities should relate to the angle between the spin's rotation axes, which we havn't determined at all, and so we work backwards from the probabilities to the angles. Actually one imagines doing this twice to separate out classical uncertainty from quantum uncertainty (see his original paper for details!). Anyway, if you do this \"experiment\" for many spins in your network, it's not clear that the angles so obtained will be consistent with each other. One might find that A and B have this angle between them, and B and C have that angle between them, which in normal 3D space would imply something about A and C's angle; but here this isn't necessarily the case. Penrose, however, shows that in the limit of big networks and high spin-$j$, that the angles between the spins become consistent with each other as if there were all embedded consistently in an emergent 3D geometry. \n",
    "\n",
    "Such ideas have been explored in other forms in loop quantum gravity. Again, we'll save the details for another time, but for example, one can consider the tensor product of a bunch of spins, and demand that they live in the angular momentum 0 subspace. For example, we've seen that the spin-$0$ subspace of 4 spin-$\\frac{1}{2}$ particles is 2D (it's just a qubit in disguise!). If you do this, then the spins act like an \"intertwiner,\" an angular momentum preserving interaction vertex, and moreover the spins can be interpreted as the faces of a *quantum polyhedron* living at that vertex, where the $j$ values now refer to the areas of the face. Indeed, it turns out the best way to quantize polyhedra is in terms of Minkowski's theorem, which says that a polyhedron is uniquely specified by the normal vectors to each of its faces, multiplied by their areas, all of which sum to 0 if the polyhedron is closed. But we digress... Another time!\n",
    "\n",
    "(Okay one more thing: I recently learned there's an intimate relationship between quantum spin and Bezier curves, the components of the $\\mid j, m \\rangle$ vector being like the control points of a complexified Bezier curve! What!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "For our final destination in this tour of spin angular momentum theory (which itself is just one chapter in our larger story about \"atoms\"), we have to discuss the \"Jordan-Schwinger\" representation of a spin, as a fixed energy subspace of two quantum harmonic oscillators. \n",
    "\n",
    "A brief review of the quantum harmonic oscillator. \n",
    "\n",
    "It's hamiltonian is basically: $H = \\frac{1}{2}(P^{2} + Q^{2})$, where $P$ is the momentum operator and $Q$ is the position operator. One great thing to do is define the creation and annihilation operators:\n",
    "\n",
    "$a = \\frac{1}{\\sqrt 2} (Q + iP)$\n",
    "\n",
    "$a^{\\dagger} = \\frac{1}{\\sqrt 2} (Q - iP)$\n",
    "\n",
    "So that: $Q = \\frac{1}{\\sqrt 2} (a^{\\dagger} + a)$ and $P =  \\frac{1}{\\sqrt 2} (a^{\\dagger} - a)$. Note that $PQ - QP = i$. \n",
    "\n",
    "What's nice about them is that you can interpret them as adding or subtracting a \"quantum\" from the oscillator, kicking it up to a higher or lower energy state. So if you can get the 0 quantum state, the ground state of the oscillator, then you can get all the other states by repeated action of the creation operator. \n",
    "\n",
    "The number operator, which counts the number of quanta, is $N = a^{\\dagger}a$, and the hamiltonian can be rewritten $H = N + \\frac{1}{2}$.\n",
    "\n",
    "Notice:\n",
    "\n",
    "$ N = \\frac{1}{\\sqrt 2}(Q - iP)\\frac{1}{\\sqrt 2}(Q + iP) = \\frac{1}{2}(Q^{2} + iQP - iPQ + P^{2}) = \\frac{1}{2}(Q^{2} + i(QP - PQ) + P^{2})$, but $QP - PQ = i$, so we get $ N = \\frac{1}{2}(P^{2} + Q^{2}) + -\\frac{1}{2} = H - \\frac{1}{2}$. So $H = N + \\frac{1}{2}$.\n",
    "\n",
    "<hr >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is often developed using the formalism of position and momentum wave functions. You have a wave function $\\psi(x)$, a function from the real numbers to the complex numbers, which is square integrable, and so can be interpreted as an \"infinite dimensional vector.\" You can think of $\\psi(x)$ as $\\langle x \\mid \\psi \\rangle$, where x is a \"Dirac delta\" that spikes at position x. But the deltas have infinite norm. They don't form a basis per se; to actually calculate probabilities you need to integrate over some interval.\n",
    "\n",
    "$Q\\mid x \\rangle = x\\mid x \\rangle$\n",
    "\n",
    "$\\langle x \\mid x' \\rangle = \\delta(x - x')$ \n",
    "\n",
    "$\\int \\mid x \\rangle \\langle x \\mid dx = \\mathbb{1}$\n",
    "\n",
    "You can take the Fourier transform of $\\psi(x)$ to get $\\psi(p)$. You can use Dirac deltas that spike at momentum p, etc.\n",
    "\n",
    "$P \\mid p \\rangle = p\\mid p \\rangle$\n",
    "\n",
    "$\\langle p \\mid p' \\rangle = \\delta(p - p')$ \n",
    "\n",
    "$\\int \\mid p \\rangle \\langle p \\mid dp = \\mathbb{1}$\n",
    "\n",
    "By the nature of the Fourier duality, a spike in position means an “oscillation” across momentum space. A spike in momentum means a “oscillation” across position space. For example, $\\psi_{p}(x) = Ce^{ipx}$ where C is a constant I’ve suppressed. \n",
    "\n",
    "$\\langle x \\mid p \\rangle = e^{ipx} $\n",
    "\n",
    "$\\langle p \\mid x \\rangle = e^{-ipx} $\n",
    "\n",
    "$ \\psi(x) = \\int e^{ipx}\\psi(p) dp = \\int \\langle x \\mid p \\rangle \\langle p \\mid \\psi \\rangle dp$\n",
    "\n",
    "$ \\psi(p) = \\int e^{-ipx}\\psi(x) dx = \\int \\langle p \\mid x \\rangle \\langle x \\mid \\psi \\rangle dx$\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recall that $Q\\psi(x) = x\\psi(x)$, that the position operator acts like multiplication by x, and $P\\psi(x) = -i\\frac{d}{dx}\\psi(x)$, that the momentum operator acts like differentiation. This was one of the initial insights of quantum mechanics: promoting the classical variables $q$ and $p$ to linear operators $Q$ and $P$.\n",
    "\n",
    "We'd also like to remind you what was implied above: the inner product $\\langle \\phi \\mid \\psi \\rangle$ is now $\\int_{-\\infty}^{+\\infty} \\phi(x)^{*}\\psi(x) dx$, where the $*$ means take the complex conjugate. Square summable means that $|\\psi(x)|^{2} = \\int_{-\\infty}^{+\\infty} \\psi(x)^{*}\\psi(x) dx$ converges to a real number (and so can be normalized to 1), and thus we can think of our wave function as being an \"infinite dimensional vector.\"\n",
    "\n",
    "With this set of correspondences, we consider the time dependent Schrodinger equation for the harmonic oscillator: $H\\psi(x, t) = i\\frac{d\\psi(x, t)}{dt}$, which in this case is: \n",
    "\n",
    "$\\frac{1}{2}(P^{2} + Q^{2})\\psi(x, t) = i\\frac{d\\psi(x, t)}{dt}$, or $\\frac{1}{2}(-\\frac{d^{2}}{dx^{2}} + x^{2})\\psi(x, t) = i\\frac{d\\psi(x, t)}{dt}$. Or: $ -\\frac{1}{2}\\frac{d^{2}\\psi(x, t)}{dx^{2}} + \\frac{1}{2}x^{2}\\psi(x, t) = i\\frac{d\\psi(x, t)}{dt}$. \n",
    "\n",
    "In terms of the time independent Schrodinger equation:  $ -\\frac{1}{2}\\frac{d^{2}\\psi(x)}{dx^{2}} + \\frac{1}{2}x^{2}\\psi(x) - e\\psi(x) = 0$, where $e$ is the eigenvalue corresponding to a given energy level. There is a whole beautiful theory of differential equations and how to solve them, and in the harmonic oscillator case, one relates the Hermite polynomials to the eigenstates of the oscillator. But actually there are some tricks we can use without actually solving the equation directly--just like in the spin case!\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, I'll just tell you that the ground state of the oscillator is:\n",
    "\n",
    "$ \\psi_{0}(x) = e^{-\\frac{x^{2}}{2}}$\n",
    "\n",
    "This function $\\psi_{0} = e^{-\\frac{x^{2}}{2}}$ is interesting. It's a Gaussian: it's invariant under the Fourier transform; and it represents the best compromise you can get between knowing both position and momentum given the Heisenberg uncertainty relations.\n",
    "\n",
    "$\\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} e^{ipx}e^{-\\frac{x^{2}}{2}}dx = e^{-\\frac{p^{2}}{2}}$.\n",
    "\n",
    "We can confirm that this is the ground state by seeing if acting with the annihilator gives the 0 vector.\n",
    "\n",
    "$ a\\psi_{0}(x) = \\frac{1}{\\sqrt 2} (Q + iP) e^{-\\frac{x^{2}}{2}} = \\frac{1}{\\sqrt 2} (xe^{-\\frac{x^{2}}{2}} + (i)(-i)\\frac{d}{dx}e^{-\\frac{x^{2}}{2}}) = \\frac{1}{\\sqrt 2}(xe^{-\\frac{x^{2}}{2}} -xe^{-\\frac{x^{2}}{2}}) = 0$\n",
    "\n",
    "But is it really an eigenstate of $H$? Consider:\n",
    "\n",
    "$H \\psi_{0}(x) = (a^{\\dagger}a + \\frac{1}{2})\\psi_{0}(x) = a^{\\dagger}a\\psi_{0}(x) + \\frac{1}{2}\\psi_{0}(x)$. \n",
    "\n",
    "But we know that $a\\psi_{0}(x)= 0$, so $H \\psi_{0}(x) = \\frac{1}{2}\\psi_{0}(x)$. And so $\\psi_{0}(x)$ is an eigenvector of the harmonic oscillator hamiltonian as desired: $H$ acts on $\\psi_{0}(x)$ by multiplication by a scalar eigenvalue, in this case $\\frac{1}{2}$. And since the annihilator annihilates it, we know it is the lowest eigenvector, and we can get all the rest by using the creation operator, just like climbing a ladder: indeed, they're known as ladder operators.\n",
    "\n",
    "$\\psi_{n}(x) = \\frac{(a^{\\dagger})^{n}}{\\sqrt{n!}}\\psi_{0}(x)$\n",
    "\n",
    "This set of set of states $\\psi_{n}(x)$, the energy eigenstates, form a countable basis for our harmonic oscillator wave function. They provide a complete set of sets. In other words, we can express some state $f(x)$ as an infinite series in the energy eigenstates:\n",
    "\n",
    "$f(x) = \\sum_{n=0}^{\\infty} c_{n}\\psi_{n}(x)$, where:\n",
    "\n",
    "$c_{n} = \\frac{\\psi_{n} \\cdot f}{\\psi_{n} \\cdot \\psi_{n}} = \\frac{\\int \\psi_{n}^{*}(x)f(x)dx}{\\int \\psi_{n}^{*}(x)\\psi_{n}(x)dx}$, in other words, the projection of the function $f(x)$ onto the energy state $n$, which, just like in the finite dimensional case, gives the coordinate in that \"direction.\" \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare this to the example from before of breaking a sound wave down into its component frequencies. If we have a real, continuous, periodic function $f(x)$ defined over the interval $r$ to $s$, we can write it as a Fourier series:\n",
    "\n",
    "$ f(x) = a_{0}C_{0}(x) + \\sum_{n=1}^{\\infty} \\Big{(} a_{n}C_{n}(x) + b_{n}S_{n}(x) \\Big{)} $.\n",
    "\n",
    "Here: $C_{0}(x) = 1$, $C_{n}(x) = cos(\\frac{2\\pi n x}{T})$, and $S_{n}(x) = sin(\\frac{2\\pi n x}{T})$, where $T$ is the period. \n",
    "\n",
    "$a_{0} = \\frac{C_{0} \\cdot f}{C_{0} \\cdot C_{0}} = \\frac{\\int_{r}^{s} C_{0}(x)f(x) dx }{\\int_{r}^{s} C_{0}(x)C_{0}(x) dx }$\n",
    "\n",
    "$a_{n} = \\frac{C_{n} \\cdot f}{C_{n} \\cdot C_{n}} = \\frac{\\int_{r}^{s} C_{n}(x)f(x) dx }{\\int_{r}^{s} C_{n}(x)C_{n}(x) dx }$\n",
    "\n",
    "$b_{n} = \\frac{S_{n} \\cdot f}{S_{n} \\cdot S_{n}} = \\frac{\\int_{r}^{s} S_{0}(x)f(x) dx }{\\int_{r}^{s} S_{n}(x)S_{n}(x) dx }$\n",
    "\n",
    "It all works because sines (and cosines) of different integer $n$ values are orthogonal!\n",
    "\n",
    "Note that there are many ways of representing a function as an infinite series, often with different inner products, with different measures.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the oscillator:\n",
    "\n",
    "We can prove that the number operator $N = a^{\\dagger}a$ actually does count the quanta.\n",
    "\n",
    "First, we consider the eigenvalue equation for $N$:\n",
    "\n",
    "$N\\psi_{n} = n\\psi_{n}$\n",
    "\n",
    "In other words, on a state of definite number, the number operator acts by multiplication by $n$, the number.\n",
    "\n",
    "Let's consider acting with $N$ after we've raised the number by one: $Na^{\\dagger}\\psi_{n}$.\n",
    "\n",
    "Now it happens that $[N, a^{\\dagger}] = a^{\\dagger}$ and $[N, a] = -a$.\n",
    "\n",
    "This means: $Na^{\\dagger} - a^{\\dagger}N = a^{\\dagger}$, which means $Na^{\\dagger} = a^{\\dagger}N + a^{\\dagger}$. \n",
    "\n",
    "So we can rewrite the above as: $Na^{\\dagger}\\psi_{n} = (a^{\\dagger}N + a^\\dagger)\\psi_{n} = a^{\\dagger}N\\psi_{n} + a^\\dagger\\psi_{n}$. \n",
    "\n",
    "But by the eigenvalue equation, this is: $na^{\\dagger}\\psi_{n} + a^\\dagger\\psi_{n} = (n+1)a^{\\dagger}\\psi_{n}$.\n",
    "\n",
    "In short, $Na^{\\dagger}\\psi_{n} = (n+1)a^{\\dagger}\\psi_{n}$. $N$ knows we've raised the number by 1!\n",
    "\n",
    "So if $\\psi_{n} = (a^{\\dagger})^{n}\\psi_{0}$, then $N\\psi_{n} = n\\psi_{n}$.\n",
    "\n",
    "Similarly: $Na\\psi_{n} = aN\\psi_{n} - a\\psi_{n} = na\\psi_{n} - a\\psi_{n} = (n-1)a\\psi_{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Now notice that while $a^{\\dagger}\\psi_{n} = \\psi_{n+1}$, we actually have $a\\psi_{n} = n\\psi_{n-1}$. Here's a little proof:\n",
    "\n",
    "We have $a\\psi_{0} = 0$, for which this is the case ($n=0$). We assume: $a\\psi_{n} = n\\psi_{n-1}$. \n",
    "\n",
    "Consider $a\\psi_{n+1}$, which is really just $aa^{\\dagger}\\psi_{n}$. Now it happens that $[a, a^\\dagger] = 1$, or $aa^{\\dagger} - a^{\\dagger}a = 1$, or $aa^{\\dagger} = a^{\\dagger}a + 1$. So we can rewrite $aa^{\\dagger}\\psi_{n}$ as $(a^{\\dagger}a + 1)\\psi_{n} = a^{\\dagger}a\\psi_{n} + \\psi_{n}$. We assumed that $a\\psi_{n} = n\\psi_{n-1}$, so we have: $a^{\\dagger}n\\psi_{n-1} + \\psi_{n}$, which is just $n\\psi_{n} + \\psi_{n}$, or $(n+1)\\psi_{n}$.\n",
    "\n",
    "In other words, if $a\\psi_{n} = n\\psi_{n-1}$, then $a\\psi_{n+1} = (n+1)\\psi_{n}$, and so if it was true for $n=0$, which it is since $a\\psi_{0} = 0$, it's true for all $n+1$. Love it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "But take a look at that a second time $a\\psi_{n} = n\\psi_{n-1}$. It looks kind of like: $\\frac{d}{dz} z^{n} = nz^{n-1}$, the rule for taking the derivative!\n",
    "\n",
    "And so another way of thinking about all this is that we represent the state of a quantum harmonic oscillator as a *polynomial*, where the powers of $z$ represent the number of quanta. This analogy can be made rigorous and goes by the name the Segal-Bargmann representation. There, $a \\rightarrow \\frac{d}{dz}$ and $ a^{\\dagger} \\rightarrow z$, the latter being multiplication by $z$. There are some technicalities involved in this construction, but the long and short of it is that we can represent our wave function as a function $f(z)$ from $\\mathbb{C} \\rightarrow \\mathbb{C}$, instead of a wavefunction $\\psi(x)$ from $\\mathbb{R} \\rightarrow \\mathbb{C}$. We'll return to this idea momentarily.\n",
    "\n",
    "For now the upshot is we can conveniently work in the energy basis: aka the Fock basis, or \"occupation number basis.\" $\\mid 0 \\rangle$, $\\mid 1 \\rangle$, $\\mid 2 \\rangle$, are the states with 0, 1, 2, and three quanta respectively. In terms of a matrix representation, we have the vacuum state is just $\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ \\vdots \\end{pmatrix}$. \n",
    "\n",
    "And: \n",
    "\n",
    "$a^\\dagger =\\begin{pmatrix}           \n",
    "0 & 0 & 0 & \\dots & 0 &\\dots \\\\\n",
    "\\sqrt{1} & 0 & 0 & \\dots & 0 & \\dots\\\\\n",
    "0 & \\sqrt{2} & 0 & \\dots & 0 & \\dots\\\\\n",
    "0 & 0 & \\sqrt{3} & \\dots & 0 & \\dots\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots  & \\vdots  & \\dots\\\\\n",
    "0 & 0 & 0 & \\dots & \\sqrt{n} &\\dots &  \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots  &\\ddots \\end{pmatrix}$\n",
    "\n",
    "$a =\\begin{pmatrix}\n",
    "0 & \\sqrt{1} & 0 & 0 & \\dots & 0 & \\dots \\\\\n",
    "0 & 0 & \\sqrt{2} & 0 & \\dots & 0 & \\dots \\\\\n",
    "0 & 0 & 0 & \\sqrt{3} & \\dots & 0 & \\dots \\\\\n",
    "0 & 0 & 0 & 0 & \\ddots & \\vdots & \\dots \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\sqrt{n} & \\dots \\\\\n",
    "0 & 0 & 0 & 0 & \\dots & 0 & \\ddots \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots \\end{pmatrix}$\n",
    "\n",
    "One thing that's nice is that we can truncate the number of possible quanta in our oscillator and obtain a finite dimensional oscillator representation, although the commutation relations between $P$ and $Q$ won't be exactly satisfied. It'll be more like a particle in a box!\n",
    "\n",
    "But we should emphasize that whereas in the spin case we were dealing with a finite dimensional Hilbert space, when we consider 1D harmonic oscillator on an infinite line, we are dealing with an infinite dimensional Hilbert space: we have to upgrade our sums into integrals, and there are all sorts of interesting technicalities. \n",
    "\n",
    "And in this nice case of the harmonic oscillator, there's a natural representation on polynomials, indeed, with an unbounded number of terms--unlike the case before, where we dealt with polynomials of fixed degree (and employed our Majorana rule for infinities).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Now: it happens that we have the notion of a coherent state for the quantum harmonic oscillator, just like we had the coherent states on the sphere.\n",
    "\n",
    "$\\mid z \\rangle = e^{-\\frac{|z|^{2}}{2}} \\sum_{n=0}^{\\infty} \\frac{z^{n}}{\\sqrt{n!}}\\mid n \\rangle$, where $\\mid n \\rangle$ are all the number states. \n",
    "\n",
    "We have here a polynomial with an infinite number of terms, and notice it's just like the infinite series of $e^{x}$ from way back when, except for the square root. Indeed, it's an eigenstate of the annihilation operator: you can subtract a quanta and it doesn't make a difference! \n",
    "\n",
    "Check this out:\n",
    "\n",
    "$ \\mid z \\rangle = \\sum_{n=0}^{\\infty} c_{n}\\mid n \\rangle$\n",
    "\n",
    "$ \\mid z \\rangle = \\sum_{n=0}^{\\infty} \\mid n \\rangle \\langle n \\mid z \\rangle$\n",
    "\n",
    "But if $\\mid n \\rangle = \\frac{(a^{\\dagger})^{n}}{\\sqrt{n!}}\\mid 0 \\rangle$, then: $\\langle n \\mid  = \\langle 0 \\mid  \\frac{(a)^{n}}{\\sqrt{n!}}$.\n",
    "\n",
    "So we can make the following move:\n",
    "\n",
    "$ \\mid z \\rangle = \\sum_{n=0}^{\\infty} \\mid n \\rangle \\langle 0 \\mid \\frac{(a)^{n}}{\\sqrt{n!}} \\mid z \\rangle$\n",
    "\n",
    "And since the coherent state is an eigenvector of the annihilation operator, $a\\mid z \\rangle = z \\mid z \\rangle$. So: \n",
    "\n",
    "$ \\mid z \\rangle = \\sum_{n=0}^{\\infty} \\mid n \\rangle \\langle 0 \\mid \\frac{(z)^{n}}{\\sqrt{n!}} \\mid z \\rangle = \\ \\langle 0 \\mid z \\rangle \\sum_{n=0}^{\\infty} \\frac{(z)^{n}}{\\sqrt{n!}} \\mid n \\rangle$\n",
    "\n",
    "The length of this as a vector has to be 1, so:\n",
    "\n",
    "$1 = \\ \\mid \\langle 0 \\mid z \\rangle \\mid^{2} \\sum_{n=0}^{\\infty} \\frac{(\\mid z \\mid^{2})^{n}}{n!}$. \n",
    "\n",
    "And by the infinite series definition of $e^{x}$, we get $1 = \\  \\mid \\langle 0 \\mid z \\rangle \\mid^{2} e^{\\mid z \\mid^{2}}$.\n",
    "\n",
    "Thus is seems like $ \\langle 0 \\mid z \\rangle = e^{-\\frac{\\mid z \\mid^{2}}{2}}$, since then $\\mid \\langle 0 \\mid z \\rangle \\mid^{2} = e^{-\\mid z \\mid^{2}}$, which cancels out the $e^{\\mid z \\mid^{2}}$ to get 1.\n",
    "\n",
    "So we've derived out expression from before:\n",
    "\n",
    "$\\mid z \\rangle = e^{-\\frac{|z|^{2}}{2}} \\sum_{n=0}^{\\infty} \\frac{z^{n}}{\\sqrt{n!}}\\mid n \\rangle$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Using further trickiness, including the Baker-Campell-Hausdorff formula, we can derive this expression for a coherent state:\n",
    "\n",
    "$\\mid z \\rangle = e^{-\\frac{|z|^{2}}{2}}e^{za^{\\dagger}}e^{-z^{*}a}\\mid 0 \\rangle$, where $\\mid 0 \\rangle$ is the vacuum state which we are \"squeezing.\"\n",
    "\n",
    "The average number of quanta in a coherent state is just $|z|^{2}$. It's expected position is just (up to some factor) $z + z^{*}$, and it's expected momentum is just $ z - z^{*}$. \n",
    "\n",
    "If you look at their behavior, they act as little coherent wavepackets closely resembling classical particles (or classical electromagnetic waves), maintaining their shape as they zip along. This is just like how the spin coherent states closely resemble the classical states of a spinning particle, all the stars along one axis.\n",
    "\n",
    "And similarly, any state of the oscillator can be written in terms of all the $\\mid z \\rangle$'s:\n",
    "\n",
    "$\\frac{1}{\\pi} \\int \\mid z \\rangle \\langle z \\mid d^{2}z = \\mathbb{1}$, where $d^{2}z = d\\mathbb{R}(z)d\\mathbb{I}(z)$. \n",
    "\n",
    "In other words, each coherent state corresponds to a *complex number*, a point in the plane (just as before each spin coherent state corresponded to a point on the sphere). And just as we could use the spin coherent states over the sphere as a basis, we can use the oscillator coherent states over the plane as a basis. When you look at the time evolution of a coherent state itself, it makes a perfect circle in this plane.\n",
    "\n",
    "Furthermore just as in the case of the sphere, it is interesting that we are able to break down the quantum system in a basis consisting of *the most classical states*. (Ps. there's an interesting relationship to \"wavelets!\") \n",
    "\n",
    "In other words, by using coherent states, we can turn our wavefunction $\\psi(x) = \\langle x \\mid \\psi \\rangle$, which is a function of a real number, into a function of a complex number $\\psi(z) = \\langle z \\mid \\psi \\rangle$, which is actually how we get our polynomial (from $\\mathbb{C} \\rightarrow \\mathbb{C}$) representation of the oscillator--again, cf. the Segal-Bargmann transformation for the subleties. \n",
    "\n",
    "In the spin case, it's interesting that when we consider the coherent state wave function on the sphere, it's completely characterized by the points opposite to the Majorana stars, in other words, by the places of 0% probability (for all the stars to be found in that location, indeed, for the spin to be in a \"classical state\" pointing in that direction). Similarly, in the harmonic oscillator case, we can use the coherent state representation to work with a polynomial, and can characterize the state by its 0% probability points, 0% probability, that is, to be in certain \"most-classical\" coherent states (with a given position and momentum). (One difference between the two cases (spin and oscillator) is that on the sphere there is a notion of  antipodal points, so that the Majorana stars are on opposite sides of the sphere from the 0% points.)\n",
    "\n",
    "In other words, we seem to be able to define a quantum state in terms of *which classical states it definitely isn't*, by a kind of negative definition. \n",
    "\n",
    "What's funny is that: while I may have an intuitive difficulty understanding how something can be in a superposition of being in \"multiple places at once,\" I have no problem understanding how something *can't* be in multiple places at once. So that it actually seems more sensible to define thing in terms of where they aren't rather than where they are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Anyway, check out a (truncated) 1D oscilllator in [oscillator.py](code/oscillator.py). You can set the maximum energy value, and view the amplitudes at each location along the line as it evolves under the oscillator hamiltonian, as well as the probabilities (in red). Use \"0\", \"1\", \"2\", \"3\", etc, to explore the different number states. Use \"i\" to generate a random state. And finally, use \"c\" to generate a random coherent state! The yellow dot shows the expected value of the position operator on the current state.\n",
    "\n",
    "For the energy states, you'll see something like:\n",
    "\n",
    "![](img/oscillator_eigenstates.jpg)\n",
    "\n",
    "Note that ignoring the endpoints, the $0$ state has 1 hump, the $1$ state has $2$ humps, the $2$ state has $3$ humps. Recall the harmonics of a vibrating string.\n",
    "\n",
    "Also check out [coherent_picker.py](code/coherent_picker) where you can drag a point around the plane and see the corresponding coherent state. And [coherent_basis](code/coherent_basis.py) which is just like [oscillator.py] except it shows you the amplitudes for each coherent state in the plane, given the current state.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we have a 1D quantum harmonic oscillator. We can view it as a little guy that \"counts\" quanta: we can add quanta to it, subtract quanta from it, measure the number of quanta. The more quanta, the higher the energy. And a general state of the oscillator is a superposition of different numbers of quanta. What is a quantum? Here, it's like a nugget of energy. It doesn't have an identity of its own: it's like the idea of a pebble.\n",
    "\n",
    "Now here's a very important connection.\n",
    "\n",
    "One of the simplest ways of understanding quantum field theory, at least at first, is via something called \"second quantization.\" Basically, if you start with a quantum system living in some Hilbert space of dimension $d$, then you can construct a theory of a *variable number of indistinguishable \"copies\" of that system* by introducing a quantum harmonic oscillator for each basis state of the original quantum system. Hence, second quantization. (We won't get into the eventual difficulties with this view as regards QFT as a whole.) \n",
    "\n",
    "The oscillators count the number of particles in the state it represents. And because we use quantum harmonic oscillators to count them, the particles as a whole will always be indistinguishable, like quanta in a harmonic oscillator. For a bosonic field, there can be any number of particles in the same state, and the particles will always be in the permutation symmetric state. For a fermionic field, there can be at most one particle in a given state, and the particles will always be in the permutation antisymmetric state.\n",
    "\n",
    "It happens that our current theories of physics regard all \"particles\" as quanta of some quantum field, as indistinguishable nuggets, which can be counted. \n",
    "\n",
    "In \"field theory\" proper, one starts with a first quantized quantum wave function, with an amplitude at each position (or momentum). And then one second quantizes, imagining a quantum harmonic oscillator at each location, counting the number of particles at that location (or in that momentum mode), and indeed: this is like a quantized model of a field, with little oscillating springs at each point. And then one can add other things to the first quantized state besides \"position,\" like spin, and even make it relativistic. (The difficulty comes in dealing with interactions.)\n",
    "\n",
    "But actually, the simplest \"quantum field theory\" involves second quantizing a little spin-$\\frac{1}{2}$ particle. It has two states, and so we introduce two quantum harmonic oscillators. It's like the first oscillator keeps track of the number of $\\uparrow$ quanta, and the second oscillator keeps track of the number of $\\downarrow$ quanta. And we'll get a theory of a variable number of permutation symmetric spin-$\\frac{1}{2}$'s. But we know what a permutation symmetric state of spin-$\\frac{1}{2}$'s is! It's a spin-$j$ particle! And so, we can look at our double oscillator construction as a model of spin with *variable $j$*, where the $j$ value can change, and indeed, we can have a superposition of different $j$ values.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could write this out in \"Fock\" notation, but let's use polynomials instead. Given two oscillators states (coeffcients suppressed):\n",
    "\n",
    "$f(z) = z^{0} + z^{1} + z^{2} + z^{3} + \\dots$\n",
    "\n",
    "$g(w) = w^{0} + w^{1} + w^{2} + w^{3} + \\dots $\n",
    "\n",
    "We can tensor them:\n",
    "\n",
    "$F(z, w) = z^{0}w^{0} + z^{0}w^{1} + z^{0}w^{2} + z^{0}w^{3} + \\dots + z^{1}w^{0} + z^{1}w^{1} + z^{1}w^{2} + z^{1}w^{3} + \\dots + z^{2}w^{0} + z^{2}w^{1} + z^{2}w^{2} + z^{2}w^{3} + \\dots + z^{3}w^{0} + z^{3}w^{1} + z^{3}w^{2} + z^{3}w^{3} + \\dots$\n",
    "\n",
    "But this can be rearranged:\n",
    "\n",
    "$F(z, w) = \\Big{\\{} z^{0}w^{0} \\Big{\\}} + \\Big{\\{} z^{1}w^{0} + z^{0}w^{1} \\Big{\\}} + \\Big{\\{} z^{2}w^{0} + z^{1}w^{1} + z^{0}w^{2} \\Big{\\}} + \\Big{\\{} z^{3}w^{0} + z^{2}w^{1} + z^{1}w^{2} + z^{0}w^{3} \\Big{\\}} + \\dots$\n",
    "\n",
    "So that we see that the two variable polynomial is a sum of *homogenous* polynomials, of degree 0, 1, 2, 3, 4... So that each sector of the Hilbert space corresponding to a given a fixed $n$ can be interpreted as a spin-$\\frac{n}{2}$ state. In other words, $n$ is just $2j$, the number of stars.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we can upgrade any 2x2 operator on spin-$\\frac{1}{2}$'s to act globally on the whole space via simple map:\n",
    "\n",
    "$ \\textbf{O} = \\sum_{i, j} a_{i}^{\\dagger} O_{i, j} a_{j} $\n",
    "\n",
    "Or: $\\textbf{O} = \\begin{pmatrix} a_{0}^{\\dagger} & a_{1}^{\\dagger} \\end{pmatrix} \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\begin{pmatrix} a_{0} \\\\ a_{1}\\end{pmatrix}$, where the $a_{i}$'s and $a_{i}^{\\dagger}$'s and recall are matrices.\n",
    "\n",
    "If we upgrade the X operator, it will act as an X operator on each of the spin-$j$ subspaces. If we use it to rotate, it'll rotate them all at once, although at a speed proportional to the $j$ value.\n",
    "\n",
    "We can also form a creation operator that creates a star at a given location. Given some spinor $\\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix}$, the star creation operator is $a_{star}^{\\dagger} = \\alpha a_{0}^{\\dagger} + \\beta a_{1}^{\\dagger}$. Thus we can decompose a spin-$j$ state into $2j$ spinors, and so lift a constellation into the double harmonic ocillator Hilbert space. Or we can form a homogenous polynomial in the creation operators:\n",
    "\n",
    "$ a_{constellation}^{\\dagger} = \\sum_{i=0}^{2j} \\frac{c_{i}}{\\sqrt{i!(2j-i)!}} (a_{0}^{\\dagger})^{2j-i}(a_{1}^{\\dagger})^{i} $\n",
    "\n",
    "where the $c_{i}$'s are the components of the $\\mid j, m \\rangle$ state: $\\begin{pmatrix} c_{0} \\\\ c_{1} \\\\ c_{2} \\\\ \\vdots \\end{pmatrix}$. Majorana returns! In fact, Schwinger learned about Majorana's representation at some point in the 30's and 40's, and it bugged him so much he invented a lot of this.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we're working with an oscillator representation, it's interesting to consider the meaning of the position operators associated to each oscillator. If we imagine the axes of the oscillators to be at right angles, so that we treat them as a 2D harmonic oscillator, and if one examines the eigenstates of the X, Y, Z operators, one finds that they correspond to diagonal/antidiagonal oriented state, circular states, and vertical/horizontal oriented states in the plane. This immedietly makes one think of the polarization of light.\n",
    "\n",
    "Indeed, imagine a light wave is rushing toward you. It has to move forward at the speed of light, as always, but it can oscillate in the plane orthogonal to its motion. This gives light a corkscrew character, and this is called its polarization. You can send light through a polarizing filter to filter out horizontally polarized light, circularly polarized light, etc. And out of nowhere, we have a model of the polarization of light, oscillating in the 2D plane orthogonal to its motion, which somehow involves the sphere. (Precusors include: the \"Poincare sphere.\")\n",
    "\n",
    "If we imagine the simplest model of polarization, and consider how the light can oscillate, it'll form an ellipse in the plane. There is an intimate connection between the sphere and the ellipse. Since what is an ellipse, but a circle seen askew in 3D?\n",
    "\n",
    "![](img/polarization_ellipse.jpeg)\n",
    "\n",
    "Indeed, if you have a qubit quantized along the Y axis (in other words, the left/right circularly polarized axis), if you rotate its overall phase, while taking the real parts of the two components to be $(x, y)$ points on the plane, it makes the appropriate ellipse. There is a relationship here to the old theory of epicycles. Consider that you can draw an ellipse by oscillatory movement horizontally and vertically, at some phase relative to each other. A point is traces out along the horizontal axis, and a point is traced out along the vertical axis: and you sum them to get the point in the plane. Or you could use oscillator movement at $45^{\\circ}$ from that, by diagonal and antidiagonal phase oscillations; or by two points making a left handed circle and a right handed circle, phased from each other, and the two locations added. This one way of interpreting the geometry of a spinor, and the meaning of the Z, X, and Y bases respectively.\n",
    "\n",
    "So we have a model for the polarization state of a photon, ignoring its momentum, in fact, of severeal photons, all with the same momentum. Each photon has a qubit representing its polarization state, and photons are a bosonic field, so the qubits must be permutation symmetric. (A photon is technically a spin-$1$ particle, but because it's massless, it has only two possible states, hence its polarization is described by a qubit.) And so everything makes sense. And we appreciate once more the deep connection between the plane and the sphere.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway, check out [spin_oscillators.py](code/spin_oscillators.py)! One can choose a max number of quanta in each of the two oscillators, as well as a random spin state to be loaded into the double oscillator Hilbert space, and a Hamiltonian to evolve with. One sees above a red sphere representing the original spin state (just to make sure it's loaded in correctly!), and below a series of blue spheres representing the spin-$0$, spin-$\\frac{1}{2}$, spin-$1$, $\\dots$ states that the Hilbert space decomposes into. Their opacity is just the norm of that sector. In the middle, one sees the plane, with little arrows at each point representing the amplitude at that location. Using the keyboard, one can measure the X, Y, Z, N (number), and Q (position) operators with \"x\", \"y\", \"z\", \"n\", and \"q\". And with \"i\" one can reset to a random state. Play around with it!\n",
    "\n",
    "Before we go, we should mention: Spin is all about representations of the group SU(2), which is the double cover of 3D rotations. Instead of using SU(2), we could use SU(3), which acts on 3D complex states, and then we'd have 3 harmonic oscillators, but actually we'd need 6, since SU(3) is rank 2. And so on, and so forth. Generally speaking, we can construct theories of a variable number of indistinguishable \"particles\" with different symmeteries. The oscillator space, just like in the spin case, can be interpreted as a superposition of possible higher order states, each of which can be represented by an unordered collection of states *to be symmeterized*, corresponding to the \"roots\": thus the atomic pattern continues.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, it's time to conclude. \n",
    "\n",
    "We began (1) by investigating our most basic idea of a \"pebble.\" We could place a pebble somewhere, and we could take it away. To communicate with a pebble, we had to agree on whether presence or absence would be significant. \n",
    "\n",
    "We then engaged in a mathematical dialectic. We imagined that anything we could do once, we could do again. So we could place another pebble, and another, and another. And make a little pile of indistinguishable pebbles which we could also take away from. And so we invented the counting numbers (2). The rule was we could repeat an action, but we always had to be able to go backwards too. To communicate with a counting number, we have to agree on what number we start counting from. We can conceive of this as a contextualization of our original pebble: *this* pebble is actually the 4th pebble, if you've been keeping count, and to keep count is: to build up a little pile. So the pile is a contextualization of the pebble.\n",
    "\n",
    "Then (3), we could imagine repeating \"counting\" itself, counting \"all at once,\" and so we invented addition, or combining piles. We had to have an inverse, and so we invented the negative numbers, when it became clear that we could subtract past 0. And thus, we found the \"integers.\" To communicate with an integer, we have to agree on what is 0, and also which direction we're in, positive or negative.\n",
    "\n",
    "Then (4), we imagined iterating addition to get multiplication, whose inverse is division. We thus found the rational numbers, or piles of \"prime pebbles.\" We can now yet further contextualize: we can specify a rational number which translates between your units and my units, between our different ideas of \"1\". We also noticed that allowing division by 0 wraps the number line into a circle.\n",
    "\n",
    "Then (5), we imagined iterating multiplication to get exponentiation, whose inverse is root-taking. We thus discovered the irrational numbers like the $\\sqrt 2$, but also the complex numbers $a + b\\sqrt{-1}$. We could thus rotate between two coordinate axes, turning irrationals into rationals, and back. We investigated the meaning of a \"limit\" and how at this stage the numbers turn reflexive, leading us to reflect on the general theory of computation and its limitations. We observed that no single set of logical atoms which are powerful enough to axiomatize arithmetic is complete in the sense that it can prove all true theorems about itself, and indeed, one such undecidable statement is the consistency of that formal system itself, in other words, if it leads to a contradiction. In other to prove the consistency of such a logical system, one as to move to a larger, more powerful system, adding axioms, which leads to yet other undecidable truths, which can be decided with yet more axioms. The point being is that: one can't start from a single set of axioms and rules for inference and imagine a machine trying out every possible rearrangement of symbols and thus proving all possible theorems. And so we proved that conceptually, there can't be a single set of \"master concepts\" from which all concepts can be mechanically derived. Hence, one requires a *dialectical* unfolding of mathematical ideas alongside the purely deductive. And indeed, that's exactly what we've been doing.\n",
    "\n",
    "For example, you could spend all day thinking about the nature of probability in terms of probability theory and you'd never be able to derive the surprising way that probabilities enter into our theory of physics, and how when they appear they are often intimately connected in surprising ways with, for example, geometry.\n",
    "\n",
    "Then (6), we began by considering an unordered set of complex numbers, which we associated to points on the plane/sphere, and realized we could interpret them as the roots of a polynomial, giving us a yet higher order version of the idea of a \"pile of pebbles\": an *equation*. We developed an interpretation of polynomials as \"quantum states,\" indeed, as the states of spin-$j$ particles. Polynomials brought with them the idea of vector spaces, and we realized that polynomials were only defined up to a set of basis vectors, and that Hermitian matrices, not necessariy commuting, which are observables in quantum mechanics, provide such basis sets via their eigenvectors. And so, to give context to our polynomials, to correctly communicate a quantum state, we had to specify a set of basis polynomials (which themselves provide context for their roots). Linear algebra provides the theory of generalized \"perspective switches,\" and we realized we could generalize our idea of perspective to that of an \"experimental situation,\" by which a state is filtered probablistically into outcome states, which provide a complete basis for the state: re the Stern-Gerlach apparatus. And we realized the importance, therefore, of unitary representations. \n",
    "\n",
    "Vector spaces, as well, bring with them the idea of the tensor product, and we realized that the symmetric tensor product of $2j$ spin-$\\frac{1}{2}$ states gives us a representation of a spin-$j$ state. And this was interesting because it involved entanglement between potentially spatially separate systems. In one of the great twists of all time, entanglement proves that any simple reductionism can't work in science. What particles get entangled, there is more information in the whole than in the parts. For example, in the antisymmetric state, two spin-$\\frac{1}{2}$ particles are maximally uncertain with regard to their individual rotation axis, but their entanglement means that they must always point in the opposite direction. So that if one is measured to be $\\uparrow$, the other one must be $\\downarrow$ in any direction. Of course, through repeated experiementation on the two particles, one could precisely determine the quantum state of the whole: that it's in the antisymmetric state. But for each instance of the experiment, there is more information contained in the two particles together, in their \"jointness,\" than can be separated into two spatially separate parts. To wit, we found that our constellation was encoded not individually in any of the symmetric spin-$\\frac{1}{2}$ particles, but in the entanglement between them.\n",
    "\n",
    "This was foreshadowed in the holistic relationship between the roots of a polynomial and its coefficients. And indeed, precisely because of that: even though we might have a situation like $2j$ disparate permutation symmetric particles, where the entangled whole is greater than its parts, from another point of view the same situation can be described as a simple juxtaposition: a product of roots, constellated on the sphere. \n",
    "\n",
    "We digressed to discuss the theory of Clebsch-Gordan coefficients, and the idea that the tensor product of a bunch of spins could be split into separate sectors, turning the AND of the tensor product into the OR of a choice. And so we arrived at the theory of angular momentum conserving interactions with allusions to spin networks, which by the way, can be generalized to other types of interactions that conserve other quantities besides angular momentum.\n",
    "\n",
    "We then discussed the idea of second quantization. We realized that polynomials (without the Majorana interpretation, in other words, generally infinite dimensional) also provide a representation of a quantum harmonic oscillator, full of indistinguishable, countable energy quanta. And we imagined introducing a quantum harmonic oscillator to each degree of freedom of a first quantized quantum system. In our case, we introduced two harmonic oscillators, one each for the $\\uparrow$ state and the $\\downarrow$ state of a spin-$\\frac{1}{2}$. And the fixed number subspaces of this Hilbert space turned out to correspond to spin-$0$, spin-$\\frac{1}{2}$, spin-$1$, $\\dots$ Hilbert spaces, each of them indeed being a permutation symmetric tensor product of spin-$\\frac{1}{2}$'s.\n",
    "\n",
    "And so we developed a representation capable of expressing a superposition of spins with different $j$ values, which was also a representation of the polarization of light, and in either case was a theory of indistinguishable particles. All known actual particles are of this type, quanta of some quantum field, albeit more complex. \n",
    "\n",
    "From this point of view, we can rephrase our theory of spin in terms of the repeated measurements of \"the number of quanta in the $\\uparrow$ oscillator\" and \"the number of quanta in the $\\downarrow$ oscillator,\" and that due to second quantization, we can think about any measurement, in some sense, as being reducible to the measurement of *some* number operator. And so, we've come full circle: we can now contextualize our pebbles as counting the number of quanta of some mode of a quantum field. Indeed, we could say that the world is conceptually made of \"pebbles\" insofar as we can use pebbles, appropriately contextualized, to represent it. And any actual clay pebble has emerged in some limit of this quantum theory.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that is also clear is that there can be many perspectives conceptually on the same quantum system. We have a constellation. Is it a spin-$j$ particle? Is it $2j$ spin-$\\frac{1}{2}$'s, is it two quantum harmonic oscillators, is it the polarization of a beam of photons? The interpretation is physically fixed by how the system interacts with the rest of the world; and conceptually each new  interpretation brings with it a whole unheralded set of ideas and connections to the rest of the world.\n",
    "\n",
    "I should emphasize, however, that there is a powerful notion of identity that persists through different physical representations. If my spin is entangled with other spins, then if I split it into symmeterized spin-$\\frac{1}{2}$'s, then these guys as whole will still be entangled with the rest of the world in the same way. So that even if something is transformed into a different physical system, it still retains its unique connection to the rest of the universe. To wit, I can load a given quantum state into a quantum computer made of spins, of light, of whatever, and this won't in principle affect its entanglement in anyway. And as we've seen we can simulate light-based operations on spins, and spin-based operations on light! So when you download something from the quantum internet, it really is *that unique non-clonable* quantum state, and not merely a *representation*, a *copy* of it, as would be the case if you loaded some classical data into your computer.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the story isn't over yet.\n",
    "\n",
    "When one works in relativistic quantum field theory, a basic demand is that the vacuum state (with no particles) is Lorentz invariant. In other words, translated, rotated, boosted observers all agree on the vacuum state, indeed, on the idea of \"what is a particle.\" This theory leads to Wigner's classification scheme. The idea is that what we mean by a \"particle\" anyway is whatever is invariant, or the same, whether we rotate it, whether we translate it, whether we translate by it, whether we see it while moving at top speed, etc. In other words, we define a particle in terms of what we can do that leaves it the same, that thing which is invariant underneath the different perspectives we might have on it, in this case, spatio-temporal perspectives. Hence the importance of group theory. (Sidebar: today in the field of neural networks, people are starting to build networks which explictly respect the underlying group structure of some domain, the classic example being learning representations of images that are translation invariant, and so forth. The idea, of course, being that a neural network should be able to recognize the identity of something even if it's seen askew--and you can really help it along if you make sure its representation is invariant under some group.)\n",
    "\n",
    "But when one moves to field theory in a curved space, one must employ (not necessarily unitary) symplectic transformations between perspectives. Famously, in the Unruh effect, while a stationary observer in the vacuum measures 0 particles, an accelerated observer experiences a different vacuum state, indeed, one with a non-0 number of particles! A symplectic transformation is one that maps creation and annihilation operators to different creation and annihilation operators while preserving the fact that they are, indeed, creation and annihilation operators. So that the $a/a^{\\dagger}$'s in the accelerated reference frame are built out of the $a/a^{\\dagger}$'s in the rest frame, in a particular way relating to the acceleration. \n",
    "\n",
    "For example, there is a class of symplectic transformations known as Bogoliubov transformations, which can turn any Hamiltonian quadratic in its creation and annihilation operators into a simple oscillator Hamiltonian: $\\sum_{i} a^{\\dagger}a$, etc. This can be used in condensed matter as well to describe how in certain systems electrons pair up to rove around as meta-particles. So that: *what is one set of particles from one point of view may be another set of particles from another point of view*.  \n",
    "\n",
    "This reaches its culmination in holographic theory, where one has, for example, a conformal field theory on the boundary of some space (like on the surface of the sphere) being from another point of view a gravitational theory in the interior of that space (like in the interior of the sphere), usually an anti-DeSitter space, one with negative curvature, so that signals going off to infinity, return in finite time--just like the inside of a black hole. Indeed, that was the motivation: one wants to regard the seemingly inaccessible quantum state of the interior of the black hole (including the things that fall into it) as being, from another perspective, the quantum state that lives on a surface, the event horizon (and also the Hawking radiation). In these models, there is an interesting connection between phenomena that extend across large scales of the boundary and phenomena occur deep in the interior of bulk of the \"emergent spacetime.\"\n",
    "\n",
    "And so we realize that even a quantum field has to contextualized with reference to some observer: one inside the black hole vs one outside, in terms of their different notions of space, time, and particle.\n",
    "\n",
    "Indeed, step by step, as it has unfolded, our story has been as much about translating between the perspective of observers (so that communication can be successful) as it has been about the pebbles which are passed between them. And so we have to ask: What is an observer, anyway? We have a theory that allows observers to come to agreement about the way the world is independent of their perspectives, using mathematics to represent the relationship between their points of view, so that they don't get out of sync. But the observers themselves, as it were, stand outside the theory as such, as *users* of the theory, which provides a reliable means of guaranteeing communication and agreement. What more can we say about them?\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you're interested in learning more about the Majorana stars, it's worth noting that you can calculate a lot of crucial things just from the stars alone. There are formulas for the inner product given two constellations; you can derive the equations for the individual time evolution of the stars from the Hamiltonian; you can calculate from the movement of the stars, the areas swept out by them and so forth, the so-called geometric phase. You can even treat generating random polynomials as a way of sampling constellations, and use this to analyze astronomical statistics, to see if there is a divergence from randomness in the intensities arriving from different directions. One of the earliest use of this kind of thinking was in dealing with the symmetry groups of crystals. Maxwell employed something similar to the Majorana construction, expanding the electromagnetic field at a given point in terms of \"multipole vectors.\" And much much more. \n",
    "\n",
    "Indeed, there is something kinda magical about the mathematics behind quantum spin. It's almost too easy, the sphere being the center of a remarkable series of coincidences. It's quite amazing that we can view a quantum spin-$j$ state as a juxtaposition of $2j$ classical states of a spinning top. There is a theory that generalizes this idea called \"Geometric Quantization,\" which is worth looking into: one investigates under what conditions copies of a classical system can be interpreted as states of a corresponding quantum system. \n",
    "\n",
    "<hr>\n",
    "\n",
    "And finally, just for fun, an open conjecture: The Atiyah-Sutcliffe conjecture.\n",
    "\n",
    "It says: if you arrange n non-coincident points in 3D, and then imagine a little sphere around each point, and imagine drawing straight lines between the points, when lines intersect the spheres, put a star at each intersection point. So each point has a constellation on a sphere associated to it which is its \"view\" of the other points. So we have $n$ constellations, each of $n-1$ stars. We can interpret these $n-1$ stars as an $n$ dimensional spin state, or as polynomials. Atiyah has conjectured, and no one has found a counterexample, that these states always form a linearly independent basis for constellations of $n-1$ stars. In other words, the mutual views of points arranged in 3D always form a linearly independent basis of the space of possible views. Of course, not all collections of constellations form consistent views. Nor is this in general an orthogonal basis, and so the components can't be interpreted so neatly as probability amplitudes. But given a $n-1$ star constellation, we can express it in the basis provided by a collection of $n$ views, and so give a kind of weight to the degree to which that constellation is \"at\" those vantage points.\n",
    "\n",
    "These and other facts make one reflect upon the truth that our basic experience of being situated in the world is not to be \"at a position\" per se, but instead: to be surrounded by a sphere of incoming momenta, the \"celestial sphere,\" carrying views of the world to us\n",
    "\n",
    "In any case, Atiyah generalizes his conjecture to hyperbolic space, Minkowski space, curved space, more general manifolds. And I have to note that he arrived at the conjecture following up on Berry and Robbin's attempt at proving the spin-statistics theorem (which says that half-integer spin particles are antisymmetric under exchange in space (fermions) whereas integer spin particles are symmetric under exchange in space (bosons)) without invoking relativistic quantum field theory. The proof hinges on the use of the oscillator representation, using four oscillators to represent two spins, and building X, Y, Z rotation operators that act *across* the spins, rotating the one into the other.)\n",
    "\n",
    "At another time, we'll visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VPython",
   "language": "python",
   "name": "vpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
